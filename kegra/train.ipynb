{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/user1/.conda/envs/new_traffic6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/user1/.conda/envs/new_traffic6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/user1/.conda/envs/new_traffic6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/user1/.conda/envs/new_traffic6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/user1/.conda/envs/new_traffic6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/user1/.conda/envs/new_traffic6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sklearn\n",
    "from keras.utils.np_utils import *\n",
    "from keras import layers\n",
    "from keras import backend as K \n",
    "from keras.layers import Input, Dropout, RNN, Dense, Concatenate, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from layers.graph import GraphConvolution\n",
    "from utils import *\n",
    "import labels\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data of GCN\n",
    "### road feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 6 nodes, 6 edges, 42 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((6, 42), (6, 40))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET = 'cora'\n",
    "FILTER = 'localpool'  # 'chebyshev'\n",
    "MAX_DEGREE = 2  # maximum polynomial degree\n",
    "SYM_NORM = True  # symmetric (True) vs. left-only (False) normalization\n",
    "NB_EPOCH = 20000\n",
    "PATIENCE = 300  # early stopping patience\n",
    "\n",
    "# Get data|\n",
    "X, A1,A2,A3,y = load_data_bantian(dataset=DATASET)\n",
    "# y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)\n",
    "POI = {\n",
    "        '26':[0,0,0,1,0,1,1,0],\n",
    "        '63':[0,0,0,1,0,0,1,0],\n",
    "        '62':[0,0,0,1,0,0,1,0],\n",
    "        '59':[0,0,0,1,0,1,1,0],\n",
    "        '60':[0,0,0,1,0,0,1,0],\n",
    "        '61':[0,0,0,1,0,0,1,1],\n",
    "}\n",
    "data_path = '/home/user1/GCN_ori/smartTraffic/traffic_data/static_feature.npy'\n",
    "static_features = np.load(data_path,allow_pickle=True)\n",
    "\n",
    "def normalization(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    return (data - np.min(data)) / _range\n",
    "\n",
    "def get_static_feature(road_id):\n",
    "    x = static_features.tolist()[road_id]\n",
    "    return list(normalization(x))+POI[road_id]\n",
    "\n",
    "roads = [26,63,62,59,60,61]\n",
    "\n",
    "static_features = [get_static_feature(str(road)) for road in roads]\n",
    "static_features = np.array(static_features)\n",
    "\n",
    "# Normalize X\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "X.shape, static_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Levenshtein'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21799/1730059024.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mLevenshtein\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroad_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroad_id2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mid_transfer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'26'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'6513'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'63'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'6512'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'62'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'6511'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'59'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'6408'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'60'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'6409'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'61'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'6410'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Levenshtein'"
     ]
    }
   ],
   "source": [
    "def str2int(str):\n",
    "    return int(str[:2])*60 + int(str[3:])\n",
    "\n",
    "def get_encode(road_id, start_time, end_time):\n",
    "    new_timing_restday = {}\n",
    "    for key in list(timing_restday[road_id]):\n",
    "        new_timing_restday[str2int(key)] = timing_restday[road_id][key]\n",
    "    times = [key for key in new_timing_restday]\n",
    "    encode = []\n",
    "    start_time = str2int(start_time)\n",
    "    end_time = str2int(end_time)\n",
    "    for index in range(len(times)):  \n",
    "        if (times[index] <= start_time and times[index + 1] > start_time):\n",
    "            start_index = index\n",
    "            break\n",
    "    while (start_time < end_time):\n",
    "        while(start_time < times[start_index + 1]):\n",
    "            \n",
    "            timings = new_timing_restday[times[start_index]]\n",
    "            for i in range(len(timings)):\n",
    "                if (road_id == '6410' and len(timings) == 4):\n",
    "                    phase = phases_restday['6410-4'][i].replace(' ', '')\n",
    "                elif (road_id == '6410' and len(timings) == 5):\n",
    "                    phase = phases_restday['6410-5'][i].replace(' ', '')\n",
    "                else:\n",
    "                    phase = phases_restday[road_id][i].replace(' ', '')\n",
    "                encode.extend([phase for i in range(int(timings[i]))])\n",
    "            start_time += 5\n",
    "            if (start_time > end_time):\n",
    "              break\n",
    "        start_index += 1\n",
    "    return encode\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[21., 33., 21.,  7.],\n",
       "        [19., 17., 18.,  7.],\n",
       "        [19., 18., 25., 13.],\n",
       "        [30., 24., 11., 10.],\n",
       "        [27., 17., 13., 15.],\n",
       "        [19., 18., 22., 14.],\n",
       "        [17., 14., 17., 12.],\n",
       "        [17., 18., 15.,  8.],\n",
       "        [20.,  7., 13.,  5.],\n",
       "        [15., 19., 19.,  5.],\n",
       "        [15., 18.,  7.,  7.],\n",
       "        [16.,  9., 14.,  4.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getCrossFlow(df_cross, start_time, end_time):\n",
    "    start = df_cross[df_cross.time==start_time].index[0]\n",
    "    end = df_cross[df_cross.time==end_time].index[0]\n",
    "    data_N = np.array(df_cross[start:end]['North'])\n",
    "    data_W = np.array(df_cross[start:end]['West'])\n",
    "    data_S = np.array(df_cross[start:end]['South'])\n",
    "    data_E = np.array(df_cross[start:end]['East'])\n",
    "    return np.stack([data_N, data_W, data_S, data_E],axis=1)\n",
    "def getSample(roads, start_time, end_time):\n",
    "    sample = []\n",
    "    data_path = '/home/user1/GCN_ori/smartTraffic/traffic_data/cross/{}.csv'\n",
    "    for road in roads:\n",
    "        df = pd.read_csv(data_path.format(road))\n",
    "        df.fillna(0,inplace = True)\n",
    "        df = df.reset_index(drop=True)\n",
    "        data = getCrossFlow(df,start_time, end_time)\n",
    "        sample.append(data)\n",
    "    return np.array(sample)\n",
    "def getSample_for_road(road, start_time, end_time):\n",
    "    sample = []\n",
    "    data_path = '/home/user1/GCN_ori/smartTraffic/traffic_data/cross/{}.csv'\n",
    " \n",
    "    df = pd.read_csv(data_path.format(road))\n",
    "    df.fillna(0,inplace = True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    data = getCrossFlow(df,start_time, end_time)\n",
    "    sample.append(data)\n",
    "    return np.array(sample)\n",
    "\n",
    "# getSample(roads, '2020-10-30 00:00:00', '2020-10-30 01:00:00')\n",
    "getSample_for_road(26, '2020-10-30 00:00:00', '2020-10-30 01:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bb0edd725679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcar_flow_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mhour\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mday1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mday2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "days = ['2020-10-30 ', '2020-10-31 ', '2020-11-01 ', '2020-11-02 ']\n",
    "hours = ['00', '01', '02','03','04','05','06', '07', '08', '09','10', '11','12', '13','14','15', '16','17', '18', '19','20', '21','22','23', '24']\n",
    "start_time = '2020-10-30 08:00:00'\n",
    "end_time = '2020-10-30 10:00:00'\n",
    "roads = ['26','63','62','59','60','61']\n",
    "\n",
    "#4重循环\n",
    "car_flow_data = []\n",
    "labels = []\n",
    "for hour in tqdm(range(23)):\n",
    "    for day1 in tqdm(days):\n",
    "        for day2 in tqdm(days):\n",
    "            for day3 in tqdm(days):\n",
    "                for day4 in tqdm(days):\n",
    "                    for day5 in days:\n",
    "                        for day6 in days:\n",
    "                            start_hour = hour\n",
    "                            end_hour = hour + 1\n",
    "                            if(start_hour < 10):\n",
    "                                start_hour = '0'+str(start_hour)\n",
    "                            else:\n",
    "                                start_hour = str(start_hour)\n",
    "                            if(end_hour < 10):\n",
    "                                end_hour = '0'+str(end_hour)\n",
    "                            else:\n",
    "                                end_hour = str(end_hour)\n",
    "                            start_time = start_hour +':00:00'\n",
    "                            end_time = end_hour +':00:00'\n",
    "                            labels.append([[similarity(road1,start_hour +':00',end_hour +':00',road2,start_hour +':00',end_hour +':00') \n",
    "                              for road2 in roads] for road1 in roads])\n",
    "                            car_flow1 = getSample_for_road('26', day1 + start_time, day1 + end_time)[0]\n",
    "                            car_flow2 = getSample_for_road('63', day2 + start_time, day2 + end_time)[0]\n",
    "                            car_flow3 = getSample_for_road('62', day3 + start_time, day3 + end_time)[0]\n",
    "                            car_flow4 = getSample_for_road('59', day4 + start_time, day4 + end_time)[0]\n",
    "                            car_flow5 = getSample_for_road('60', day5 + start_time, day5 + end_time)[0]\n",
    "                            car_flow6 = getSample_for_road('61', day6 + start_time, day6 + end_time)[0]\n",
    "                            car_flow_data.append([car_flow1,car_flow2,car_flow3,car_flow4,car_flow5,car_flow6])\n",
    "                    \n",
    "# car_flow_feature.shape, static_features.shape\n",
    "car_flow_data=np.array(car_flow_data)\n",
    "labels = np.array(labels)\n",
    "labels.shape\n",
    "#6*6的矩阵\n",
    "# similarity('26','07:05','08:15','63','08:05','08:15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86016, 6, 6), (86016, 6, 12, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86016, 6, 6), (86016, 6, 12, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.load(\"labels.npy\")\n",
    "car_flow_feature = np.load(\"car_flow_data.npy\")\n",
    "labels.shape, car_flow_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_squart, Tensor(\"distance/Sum:0\", shape=(?, 1), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12, 4)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 12, 10)       600         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 12, 4)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "squeeze1 (Lambda)               (None, 10)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "1stNeighbor (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "2ndNeighbor (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "3rdNeighbor (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 12, 10)       600         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "GCN1_1 (GraphConvolution)       (None, 16)           176         squeeze1[0][0]                   \n",
      "                                                                 1stNeighbor[0][0]                \n",
      "                                                                 2ndNeighbor[0][0]                \n",
      "                                                                 3rdNeighbor[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "GCN2_1 (GraphConvolution)       (None, 16)           176         squeeze1[0][0]                   \n",
      "                                                                 1stNeighbor[0][0]                \n",
      "                                                                 2ndNeighbor[0][0]                \n",
      "                                                                 3rdNeighbor[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "GCN3_1 (GraphConvolution)       (None, 16)           176         squeeze1[0][0]                   \n",
      "                                                                 1stNeighbor[0][0]                \n",
      "                                                                 2ndNeighbor[0][0]                \n",
      "                                                                 3rdNeighbor[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "squeeze1_ (Lambda)              (None, 10)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "1stNeighbor_ (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "2ndNeighbor_ (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "3rdNeighbor_ (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GCN1_2 (GraphConvolution)       (None, 1)            17          GCN1_1[0][0]                     \n",
      "                                                                 1stNeighbor[0][0]                \n",
      "                                                                 2ndNeighbor[0][0]                \n",
      "                                                                 3rdNeighbor[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "GCN2_2 (GraphConvolution)       (None, 1)            17          GCN2_1[0][0]                     \n",
      "                                                                 1stNeighbor[0][0]                \n",
      "                                                                 2ndNeighbor[0][0]                \n",
      "                                                                 3rdNeighbor[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "GCN3_2 (GraphConvolution)       (None, 1)            17          GCN3_1[0][0]                     \n",
      "                                                                 1stNeighbor[0][0]                \n",
      "                                                                 2ndNeighbor[0][0]                \n",
      "                                                                 3rdNeighbor[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "static_feature (InputLayer)     (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GCN1_2_ (GraphConvolution)      (None, 1)            11          squeeze1_[0][0]                  \n",
      "                                                                 1stNeighbor_[0][0]               \n",
      "                                                                 2ndNeighbor_[0][0]               \n",
      "                                                                 3rdNeighbor_[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "GCN2_2_ (GraphConvolution)      (None, 1)            11          squeeze1_[0][0]                  \n",
      "                                                                 1stNeighbor_[0][0]               \n",
      "                                                                 2ndNeighbor_[0][0]               \n",
      "                                                                 3rdNeighbor_[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "GCN3_2_ (GraphConvolution)      (None, 1)            11          squeeze1_[0][0]                  \n",
      "                                                                 1stNeighbor_[0][0]               \n",
      "                                                                 2ndNeighbor_[0][0]               \n",
      "                                                                 3rdNeighbor_[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "static_feature_ (InputLayer)    (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatStaticFeature (Concatenat (None, 43)           0           GCN1_2[0][0]                     \n",
      "                                                                 GCN2_2[0][0]                     \n",
      "                                                                 GCN3_2[0][0]                     \n",
      "                                                                 static_feature[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatStaticFeature_ (Concatena (None, 43)           0           GCN1_2_[0][0]                    \n",
      "                                                                 GCN2_2_[0][0]                    \n",
      "                                                                 GCN3_2_[0][0]                    \n",
      "                                                                 static_feature_[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "outPut (Dense)                  (None, 1)            44          concatStaticFeature[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outPut_ (Dense)                 (None, 1)            44          concatStaticFeature_[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "distance (Lambda)               (None, 6)            0           outPut[0][0]                     \n",
      "                                                                 outPut_[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,900\n",
      "Trainable params: 1,900\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "def slice(x,index):\n",
    "    return x[:,index]\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    print(\"sum_squart,\",sum_square)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "input_shape = (12, 4)\n",
    "output_shape = (1)\n",
    "support = 1\n",
    "# 第一个输入\n",
    "feature_input = Input(\n",
    "    shape=(static_features.shape[1:]), name='static_feature')\n",
    "if FILTER == 'localpool':\n",
    "    \"\"\" Local pooling filters (see 'renormalization trick' in Kipf & Welling, arXiv 2016) \"\"\"\n",
    "#     print('Using local pooling filters...')\n",
    "    G1 = [Input(shape=(None, None), batch_shape=(None, None),sparse=True, name=\"1stNeighbor\")]\n",
    "    G2 = [Input(shape=(None, None),  batch_shape=(None, None), sparse=True, name=\"2ndNeighbor\")]\n",
    "    G3 = [Input(shape=(None, None),  batch_shape=(None, None),sparse=True, name=\"3rdNeighbor\")]\n",
    "elif FILTER == 'chebyshev':\n",
    "    \"\"\" Chebyshev polynomial basis filters (Defferard et al., NIPS 2016)  \"\"\"\n",
    "    pass\n",
    "else:\n",
    "    raise Exception('Invalid filter type.')\n",
    "X_in = Input(shape=input_shape)\n",
    "X2 = layers.LSTM(10,return_sequences=True,activation='relu')(X_in)\n",
    "H = layers.Lambda(slice, arguments={'index': -1}, name='squeeze1')(X2)\n",
    "H1 = GraphConvolution(16, 1, support, activation='relu',\n",
    "                      kernel_regularizer=l2(5e-4), name='GCN1_1')([H]+G1+G2+G3)\n",
    "H2 = GraphConvolution(16, 2, support, activation='relu',\n",
    "                      kernel_regularizer=l2(5e-4), name='GCN2_1')([H]+G1+G2+G3)\n",
    "H3 = GraphConvolution(16, 3, support, activation='relu',\n",
    "                      kernel_regularizer=l2(5e-4), name='GCN3_1')([H]+G1+G2+G3)\n",
    "Y1 = GraphConvolution(y.shape[1], 1, support, name='GCN1_2')([H1]+G1+G2+G3)\n",
    "Y2 = GraphConvolution(y.shape[1], 2, support, name='GCN2_2')([H2]+G1+G2+G3)\n",
    "Y3 = GraphConvolution(y.shape[1], 3, support, name='GCN3_2')([H3]+G1+G2+G3)\n",
    "Y = Concatenate(name=\"concatStaticFeature\")([Y1, Y2, Y3, feature_input])\n",
    "output_layer = Dense(output_shape, name=\"outPut\")(Y)\n",
    "\n",
    "# 第二个输入\n",
    "feature_input_ = Input(\n",
    "    shape=(static_features.shape[1:]), name='static_feature_')\n",
    "if FILTER == 'localpool':\n",
    "    \"\"\" Local pooling filters (see 'renormalization trick' in Kipf & Welling, arXiv 2016) \"\"\"\n",
    "#     print('Using local pooling filters...')\n",
    "\n",
    "    G1_ = [Input(shape=(None, None),   batch_shape=(None, None),sparse=True, name=\"1stNeighbor_\")]\n",
    "    G2_ = [Input(shape=(None, None),  batch_shape=(None, None),sparse=True, name=\"2ndNeighbor_\")]\n",
    "    G3_ = [Input(shape=(None, None),   batch_shape=(None, None),sparse=True, name=\"3rdNeighbor_\")]\n",
    "elif FILTER == 'chebyshev':\n",
    "    \"\"\" Chebyshev polynomial basis filters (Defferard et al., NIPS 2016)  \"\"\"\n",
    "    pass\n",
    "else:\n",
    "    raise Exception('Invalid filter type.')\n",
    "X_in_ = Input(shape=input_shape)\n",
    "X2_ = layers.LSTM(10,return_sequences=True,activation='relu')(X_in_)\n",
    "\n",
    "H_ = layers.Lambda(slice, arguments={'index': -1}, name='squeeze1_')(X2_)\n",
    "H1_ = GraphConvolution(16, 1, support, activation='relu',\n",
    "                      kernel_regularizer=l2(5e-4), name='GCN1_1')([H_]+G1_+G2_+G3_)\n",
    "H2_ = GraphConvolution(16, 2, support, activation='relu', kernel_regularizer=l2(\n",
    "    5e-4), name='GCN2_1_')([H_]+G1_+G2_+G3_)\n",
    "H3_ = GraphConvolution(16, 3, support, activation='relu', kernel_regularizer=l2(\n",
    "    5e-4), name='GCN3_1_')([H_]+G1_+G2_+G3_)\n",
    "Y1_ = GraphConvolution(y.shape[1], 1, support,\n",
    "                       name='GCN1_2_')([H_]+G1_+G2_+G3_)\n",
    "Y2_ = GraphConvolution(y.shape[1], 2, support,\n",
    "                       name='GCN2_2_')([H_]+G1_+G2_+G3_)\n",
    "Y3_ = GraphConvolution(y.shape[1], 3, support,\n",
    "                       name='GCN3_2_')([H_]+G1_+G2_+G3_)\n",
    "Y_ = Concatenate(name=\"concatStaticFeature_\")([Y1_, Y2_, Y3_, feature_input_])\n",
    "output_layer_ = Dense(output_shape, name=\"outPut_\")(Y_)\n",
    "distance = Lambda(euclidean_distance, output_shape=(6,), name=\"distance\")([output_layer, output_layer_])\n",
    "\n",
    "all_input = [X_in]+G1+G2+G3+[feature_input] + \\\n",
    "    [X_in_]+G1_+G2_+G3_+[feature_input_]\n",
    "model = Model(inputs=all_input, outputs=distance)\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    SSR = K.mean(K.square(y_pred-K.mean(y_true)),axis=-1)\n",
    "    SST = K.mean(K.square(y_true-K.mean(y_true)),axis=-1)\n",
    "    return SSR/SST\n",
    "# from sklearn.metrics import explained_variance_score\n",
    "# def evs(y_true, y_pred):\n",
    "#     return explained_variance_score(np.array(y_true), np.array(y_pred))\n",
    "# from tensorflow.python.keras.metrics import Metric\n",
    "from keras import metrics\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.001),metrics = [metrics.mean_squared_error,metrics.mean_absolute_error,metrics.binary_accuracy,r_square])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86016, 6, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = preprocess_adj(A1, SYM_NORM)\n",
    "A2 = preprocess_adj(A2, SYM_NORM)\n",
    "A3 = preprocess_adj(A3, SYM_NORM)\n",
    "# y_train = np.array([1 for i in range(6)])\n",
    "\n",
    "labels.reshape([len(labels),6,-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names\n",
    "np.array([2,2])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 117ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 0s 17ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 15ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 19ms/step\n",
      "6/6 [==============================] - 0s 14ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 15ms/step\n",
      "6/6 [==============================] - 0s 13ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 17ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 12ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 11ms/step\n",
      "6/6 [==============================] - 0s 10ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 13ms/step\n",
      "6/6 [==============================] - 0s 14ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 14ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 11ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 11ms/step\n",
      "6/6 [==============================] - 0s 12ms/step\n",
      "6/6 [==============================] - 0s 16ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 19ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 18ms/step\n",
      "6/6 [==============================] - 0s 11ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "[0.0378957  0.03693414 0.15791942 0.16666667 1.28761274]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "l = len(car_flow_feature)\n",
    "l=12000\n",
    "ll = int(l*0.8)\n",
    "ans = np.array([0,0,0,0,0])\n",
    "\n",
    "for i in range(ll):\n",
    "    graph = [car_flow_feature[i], A1,A2,A3,static_features]\n",
    "    model.fit(graph+graph,labels[i], \n",
    "                batch_size=A1.shape[0] , epochs=10, shuffle=False, verbose=0)\n",
    "cnt = 0\n",
    "for i in range(ll, l):\n",
    "    cnt = cnt + 1\n",
    "    graph = [car_flow_feature[i], A1,A2,A3,static_features]\n",
    "    res = model.evaluate(graph+graph,labels[i])\n",
    "    ans = np.sum([ans,res], axis = 0)\n",
    "print(ans/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 22 14:38:01 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 41%   27C    P8    15W / 280W |   4292MiB / 24219MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 41%   32C    P8    14W / 280W |     12MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 82%   87C    P2   249W / 280W |  11775MiB / 24220MiB |     90%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 41%   42C    P8    13W / 280W |     12MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN RTX           Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 41%   25C    P8     5W / 280W |     12MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN RTX           Off  | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 41%   29C    P8    17W / 280W |     12MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN RTX           Off  | 00000000:B4:00.0 Off |                  N/A |\n",
      "| 41%   31C    P8    13W / 280W |   5260MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN RTX           Off  | 00000000:B5:00.0 Off |                  N/A |\n",
      "| 41%   31C    P8    14W / 280W |     12MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      2658      G   /usr/bin/X                                    45MiB |\n",
      "|    0      4112      G   /usr/bin/gnome-shell                          35MiB |\n",
      "|    0     80039      C   python                                      1189MiB |\n",
      "|    0     82736      C   python                                      3007MiB |\n",
      "|    2     88598      C   python                                     11763MiB |\n",
      "|    6     82737      C   python                                      3007MiB |\n",
      "|    6     82738      C   python                                      2241MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.5191 train_acc= 1.0000 val_loss= 1.5191 val_acc= 1.0000 time= 9.6271\n",
      "Epoch: 0002 train_loss= 1.8975 train_acc= 1.0000 val_loss= 1.8975 val_acc= 1.0000 time= 0.0094\n",
      "Epoch: 0003 train_loss= 2.2486 train_acc= 1.0000 val_loss= 2.2486 val_acc= 1.0000 time= 0.0152\n",
      "Epoch: 0004 train_loss= 2.5003 train_acc= 1.0000 val_loss= 2.5003 val_acc= 1.0000 time= 0.0148\n",
      "Epoch: 0005 train_loss= 2.5939 train_acc= 1.0000 val_loss= 2.5939 val_acc= 1.0000 time= 0.0142\n",
      "Epoch: 0006 train_loss= 2.5311 train_acc= 1.0000 val_loss= 2.5311 val_acc= 1.0000 time= 0.0127\n",
      "Epoch: 0007 train_loss= 2.3661 train_acc= 1.0000 val_loss= 2.3661 val_acc= 1.0000 time= 0.0176\n",
      "Epoch: 0008 train_loss= 2.1610 train_acc= 1.0000 val_loss= 2.1610 val_acc= 1.0000 time= 0.0191\n",
      "Epoch: 0009 train_loss= 1.9552 train_acc= 1.0000 val_loss= 1.9552 val_acc= 1.0000 time= 0.0220\n",
      "Epoch: 0010 train_loss= 1.7667 train_acc= 1.0000 val_loss= 1.7667 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0011 train_loss= 1.6182 train_acc= 1.0000 val_loss= 1.6182 val_acc= 1.0000 time= 0.0157\n",
      "Epoch: 0012 train_loss= 1.5255 train_acc= 1.0000 val_loss= 1.5255 val_acc= 1.0000 time= 0.0254\n",
      "Epoch: 0013 train_loss= 1.4435 train_acc= 1.0000 val_loss= 1.4435 val_acc= 1.0000 time= 0.0137\n",
      "Epoch: 0014 train_loss= 1.3725 train_acc= 1.0000 val_loss= 1.3725 val_acc= 1.0000 time= 0.0158\n",
      "Epoch: 0015 train_loss= 1.3123 train_acc= 1.0000 val_loss= 1.3123 val_acc= 1.0000 time= 0.0189\n",
      "Epoch: 0016 train_loss= 1.2625 train_acc= 1.0000 val_loss= 1.2625 val_acc= 1.0000 time= 0.0133\n",
      "Epoch: 0017 train_loss= 1.2221 train_acc= 1.0000 val_loss= 1.2221 val_acc= 1.0000 time= 0.0234\n",
      "Epoch: 0018 train_loss= 1.1903 train_acc= 1.0000 val_loss= 1.1903 val_acc= 1.0000 time= 0.0167\n",
      "Epoch: 0019 train_loss= 1.1656 train_acc= 1.0000 val_loss= 1.1656 val_acc= 1.0000 time= 0.0220\n",
      "Epoch: 0020 train_loss= 1.1466 train_acc= 1.0000 val_loss= 1.1466 val_acc= 1.0000 time= 0.0299\n",
      "Epoch: 0021 train_loss= 1.1316 train_acc= 1.0000 val_loss= 1.1316 val_acc= 1.0000 time= 0.0237\n",
      "Epoch: 0022 train_loss= 1.1192 train_acc= 1.0000 val_loss= 1.1192 val_acc= 1.0000 time= 0.0456\n",
      "Epoch: 0023 train_loss= 1.1078 train_acc= 1.0000 val_loss= 1.1078 val_acc= 1.0000 time= 0.0278\n",
      "Epoch: 0024 train_loss= 1.0962 train_acc= 1.0000 val_loss= 1.0962 val_acc= 1.0000 time= 0.0257\n",
      "Epoch: 0025 train_loss= 1.0833 train_acc= 1.0000 val_loss= 1.0833 val_acc= 1.0000 time= 0.0273\n",
      "Epoch: 0026 train_loss= 1.0732 train_acc= 1.0000 val_loss= 1.0732 val_acc= 1.0000 time= 0.0198\n",
      "Epoch: 0027 train_loss= 1.0665 train_acc= 1.0000 val_loss= 1.0665 val_acc= 1.0000 time= 0.0190\n",
      "Epoch: 0028 train_loss= 1.0560 train_acc= 1.0000 val_loss= 1.0560 val_acc= 1.0000 time= 0.0189\n",
      "Epoch: 0029 train_loss= 1.0416 train_acc= 1.0000 val_loss= 1.0416 val_acc= 1.0000 time= 0.0196\n",
      "Epoch: 0030 train_loss= 1.0238 train_acc= 1.0000 val_loss= 1.0238 val_acc= 1.0000 time= 0.0173\n",
      "Epoch: 0031 train_loss= 1.0034 train_acc= 1.0000 val_loss= 1.0034 val_acc= 1.0000 time= 0.0175\n",
      "Epoch: 0032 train_loss= 0.9816 train_acc= 1.0000 val_loss= 0.9816 val_acc= 1.0000 time= 0.0225\n",
      "Epoch: 0033 train_loss= 0.9596 train_acc= 1.0000 val_loss= 0.9596 val_acc= 1.0000 time= 0.0174\n",
      "Epoch: 0034 train_loss= 0.9385 train_acc= 1.0000 val_loss= 0.9385 val_acc= 1.0000 time= 0.0191\n",
      "Epoch: 0035 train_loss= 0.9197 train_acc= 1.0000 val_loss= 0.9197 val_acc= 1.0000 time= 0.0170\n",
      "Epoch: 0036 train_loss= 0.9039 train_acc= 1.0000 val_loss= 0.9039 val_acc= 1.0000 time= 0.0237\n",
      "Epoch: 0037 train_loss= 0.8918 train_acc= 1.0000 val_loss= 0.8918 val_acc= 1.0000 time= 0.0193\n",
      "Epoch: 0038 train_loss= 0.8837 train_acc= 1.0000 val_loss= 0.8837 val_acc= 1.0000 time= 0.0179\n",
      "Epoch: 0039 train_loss= 0.8795 train_acc= 1.0000 val_loss= 0.8795 val_acc= 1.0000 time= 0.0170\n",
      "Epoch: 0040 train_loss= 0.8790 train_acc= 1.0000 val_loss= 0.8790 val_acc= 1.0000 time= 0.0293\n",
      "Epoch: 0041 train_loss= 0.8816 train_acc= 1.0000 val_loss= 0.8816 val_acc= 1.0000 time= 0.0200\n",
      "Epoch: 0042 train_loss= 0.8865 train_acc= 1.0000 val_loss= 0.8865 val_acc= 1.0000 time= 0.0178\n",
      "Epoch: 0043 train_loss= 0.8927 train_acc= 1.0000 val_loss= 0.8927 val_acc= 1.0000 time= 0.0170\n",
      "Epoch: 0044 train_loss= 0.8994 train_acc= 1.0000 val_loss= 0.8994 val_acc= 1.0000 time= 0.0180\n",
      "Epoch: 0045 train_loss= 0.9057 train_acc= 1.0000 val_loss= 0.9057 val_acc= 1.0000 time= 0.0119\n",
      "Epoch: 0046 train_loss= 0.9108 train_acc= 1.0000 val_loss= 0.9108 val_acc= 1.0000 time= 0.0169\n",
      "Epoch: 0047 train_loss= 0.9141 train_acc= 1.0000 val_loss= 0.9141 val_acc= 1.0000 time= 0.0193\n",
      "Epoch: 0048 train_loss= 0.9151 train_acc= 1.0000 val_loss= 0.9151 val_acc= 1.0000 time= 0.0116\n",
      "Epoch: 0049 train_loss= 0.9140 train_acc= 1.0000 val_loss= 0.9140 val_acc= 1.0000 time= 0.0131\n",
      "Epoch: 0050 train_loss= 0.9110 train_acc= 1.0000 val_loss= 0.9110 val_acc= 1.0000 time= 0.0113\n",
      "Epoch: 0051 train_loss= 0.9069 train_acc= 1.0000 val_loss= 0.9069 val_acc= 1.0000 time= 0.0128\n",
      "Epoch: 0052 train_loss= 0.9024 train_acc= 1.0000 val_loss= 0.9024 val_acc= 1.0000 time= 0.0129\n",
      "Epoch: 0053 train_loss= 0.8980 train_acc= 1.0000 val_loss= 0.8980 val_acc= 1.0000 time= 0.0249\n",
      "Epoch: 0054 train_loss= 0.8945 train_acc= 1.0000 val_loss= 0.8945 val_acc= 1.0000 time= 0.0205\n",
      "Epoch: 0055 train_loss= 0.8922 train_acc= 1.0000 val_loss= 0.8922 val_acc= 1.0000 time= 0.0176\n",
      "Epoch: 0056 train_loss= 0.8914 train_acc= 1.0000 val_loss= 0.8914 val_acc= 1.0000 time= 0.0211\n",
      "Epoch: 0057 train_loss= 0.8921 train_acc= 1.0000 val_loss= 0.8921 val_acc= 1.0000 time= 0.0109\n",
      "Epoch: 0058 train_loss= 0.8942 train_acc= 1.0000 val_loss= 0.8942 val_acc= 1.0000 time= 0.0181\n",
      "Epoch: 0059 train_loss= 0.8973 train_acc= 1.0000 val_loss= 0.8973 val_acc= 1.0000 time= 0.0201\n",
      "Epoch: 0060 train_loss= 0.9010 train_acc= 1.0000 val_loss= 0.9010 val_acc= 1.0000 time= 0.0159\n",
      "Epoch: 0061 train_loss= 0.9047 train_acc= 1.0000 val_loss= 0.9047 val_acc= 1.0000 time= 0.0210\n",
      "Epoch: 0062 train_loss= 0.9084 train_acc= 1.0000 val_loss= 0.9084 val_acc= 1.0000 time= 0.0159\n",
      "Epoch: 0063 train_loss= 0.9113 train_acc= 1.0000 val_loss= 0.9113 val_acc= 1.0000 time= 0.0122\n",
      "Epoch: 0064 train_loss= 0.9132 train_acc= 1.0000 val_loss= 0.9132 val_acc= 1.0000 time= 0.0135\n",
      "Epoch: 0065 train_loss= 0.9136 train_acc= 1.0000 val_loss= 0.9136 val_acc= 1.0000 time= 0.0127\n",
      "Epoch: 0066 train_loss= 0.9124 train_acc= 1.0000 val_loss= 0.9124 val_acc= 1.0000 time= 0.0137\n",
      "Epoch: 0067 train_loss= 0.9097 train_acc= 1.0000 val_loss= 0.9097 val_acc= 1.0000 time= 0.0201\n",
      "Epoch: 0068 train_loss= 0.9067 train_acc= 1.0000 val_loss= 0.9067 val_acc= 1.0000 time= 0.0193\n",
      "Epoch: 0069 train_loss= 0.9034 train_acc= 1.0000 val_loss= 0.9034 val_acc= 1.0000 time= 0.0221\n",
      "Epoch: 0070 train_loss= 0.8998 train_acc= 1.0000 val_loss= 0.8998 val_acc= 1.0000 time= 0.0199\n",
      "Epoch: 0071 train_loss= 0.8982 train_acc= 1.0000 val_loss= 0.8982 val_acc= 1.0000 time= 0.0204\n",
      "Epoch: 0072 train_loss= 0.8980 train_acc= 1.0000 val_loss= 0.8980 val_acc= 1.0000 time= 0.0189\n",
      "Epoch: 0073 train_loss= 0.8969 train_acc= 1.0000 val_loss= 0.8969 val_acc= 1.0000 time= 0.0185\n",
      "Epoch: 0074 train_loss= 0.8945 train_acc= 1.0000 val_loss= 0.8945 val_acc= 1.0000 time= 0.0224\n",
      "Epoch: 0075 train_loss= 0.8909 train_acc= 1.0000 val_loss= 0.8909 val_acc= 1.0000 time= 0.0202\n",
      "Epoch: 0076 train_loss= 0.8866 train_acc= 1.0000 val_loss= 0.8866 val_acc= 1.0000 time= 0.0201\n",
      "Epoch: 0077 train_loss= 0.8818 train_acc= 1.0000 val_loss= 0.8818 val_acc= 1.0000 time= 0.0215\n",
      "Epoch: 0078 train_loss= 0.8769 train_acc= 1.0000 val_loss= 0.8769 val_acc= 1.0000 time= 0.0095\n",
      "Epoch: 0079 train_loss= 0.8712 train_acc= 1.0000 val_loss= 0.8712 val_acc= 1.0000 time= 0.0171\n",
      "Epoch: 0080 train_loss= 0.8653 train_acc= 1.0000 val_loss= 0.8653 val_acc= 1.0000 time= 0.0194\n",
      "Epoch: 0081 train_loss= 0.8598 train_acc= 1.0000 val_loss= 0.8598 val_acc= 1.0000 time= 0.0200\n",
      "Epoch: 0082 train_loss= 0.8545 train_acc= 1.0000 val_loss= 0.8545 val_acc= 1.0000 time= 0.0168\n",
      "Epoch: 0083 train_loss= 0.8499 train_acc= 1.0000 val_loss= 0.8499 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0084 train_loss= 0.8463 train_acc= 1.0000 val_loss= 0.8463 val_acc= 1.0000 time= 0.0218\n",
      "Epoch: 0085 train_loss= 0.8437 train_acc= 1.0000 val_loss= 0.8437 val_acc= 1.0000 time= 0.0292\n",
      "Epoch: 0086 train_loss= 0.8418 train_acc= 1.0000 val_loss= 0.8418 val_acc= 1.0000 time= 0.0181\n",
      "Epoch: 0087 train_loss= 0.8403 train_acc= 1.0000 val_loss= 0.8403 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0088 train_loss= 0.8389 train_acc= 1.0000 val_loss= 0.8389 val_acc= 1.0000 time= 0.0175\n",
      "Epoch: 0089 train_loss= 0.8371 train_acc= 1.0000 val_loss= 0.8371 val_acc= 1.0000 time= 0.0214\n",
      "Epoch: 0090 train_loss= 0.8356 train_acc= 1.0000 val_loss= 0.8356 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0091 train_loss= 0.8343 train_acc= 1.0000 val_loss= 0.8343 val_acc= 1.0000 time= 0.0198\n",
      "Epoch: 0092 train_loss= 0.8329 train_acc= 1.0000 val_loss= 0.8329 val_acc= 1.0000 time= 0.0199\n",
      "Epoch: 0093 train_loss= 0.8310 train_acc= 1.0000 val_loss= 0.8310 val_acc= 1.0000 time= 0.0184\n",
      "Epoch: 0094 train_loss= 0.8284 train_acc= 1.0000 val_loss= 0.8284 val_acc= 1.0000 time= 0.0178\n",
      "Epoch: 0095 train_loss= 0.8243 train_acc= 1.0000 val_loss= 0.8243 val_acc= 1.0000 time= 0.0167\n",
      "Epoch: 0096 train_loss= 0.8193 train_acc= 1.0000 val_loss= 0.8193 val_acc= 1.0000 time= 0.0204\n",
      "Epoch: 0097 train_loss= 0.8137 train_acc= 1.0000 val_loss= 0.8137 val_acc= 1.0000 time= 0.0173\n",
      "Epoch: 0098 train_loss= 0.8084 train_acc= 1.0000 val_loss= 0.8084 val_acc= 1.0000 time= 0.0203\n",
      "Epoch: 0099 train_loss= 0.8043 train_acc= 1.0000 val_loss= 0.8043 val_acc= 1.0000 time= 0.0274\n",
      "Epoch: 0100 train_loss= 0.8016 train_acc= 1.0000 val_loss= 0.8016 val_acc= 1.0000 time= 0.0131\n",
      "Epoch: 0101 train_loss= 0.8003 train_acc= 1.0000 val_loss= 0.8003 val_acc= 1.0000 time= 0.0189\n",
      "Epoch: 0102 train_loss= 0.7994 train_acc= 1.0000 val_loss= 0.7994 val_acc= 1.0000 time= 0.0198\n",
      "Epoch: 0103 train_loss= 0.7984 train_acc= 1.0000 val_loss= 0.7984 val_acc= 1.0000 time= 0.0221\n",
      "Epoch: 0104 train_loss= 0.7975 train_acc= 1.0000 val_loss= 0.7975 val_acc= 1.0000 time= 0.0205\n",
      "Epoch: 0105 train_loss= 0.7963 train_acc= 1.0000 val_loss= 0.7963 val_acc= 1.0000 time= 0.0187\n",
      "Epoch: 0106 train_loss= 0.7948 train_acc= 1.0000 val_loss= 0.7948 val_acc= 1.0000 time= 0.0187\n",
      "Epoch: 0107 train_loss= 0.7936 train_acc= 1.0000 val_loss= 0.7936 val_acc= 1.0000 time= 0.0176\n",
      "Epoch: 0108 train_loss= 0.7925 train_acc= 1.0000 val_loss= 0.7925 val_acc= 1.0000 time= 0.0179\n",
      "Epoch: 0109 train_loss= 0.7911 train_acc= 1.0000 val_loss= 0.7911 val_acc= 1.0000 time= 0.0182\n",
      "Epoch: 0110 train_loss= 0.7892 train_acc= 1.0000 val_loss= 0.7892 val_acc= 1.0000 time= 0.0205\n",
      "Epoch: 0111 train_loss= 0.7864 train_acc= 1.0000 val_loss= 0.7864 val_acc= 1.0000 time= 0.0212\n",
      "Epoch: 0112 train_loss= 0.7832 train_acc= 1.0000 val_loss= 0.7832 val_acc= 1.0000 time= 0.0225\n",
      "Epoch: 0113 train_loss= 0.7800 train_acc= 1.0000 val_loss= 0.7800 val_acc= 1.0000 time= 0.0185\n",
      "Epoch: 0114 train_loss= 0.7771 train_acc= 1.0000 val_loss= 0.7771 val_acc= 1.0000 time= 0.0202\n",
      "Epoch: 0115 train_loss= 0.7755 train_acc= 1.0000 val_loss= 0.7755 val_acc= 1.0000 time= 0.0199\n",
      "Epoch: 0116 train_loss= 0.7749 train_acc= 1.0000 val_loss= 0.7749 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0117 train_loss= 0.7748 train_acc= 1.0000 val_loss= 0.7748 val_acc= 1.0000 time= 0.0200\n",
      "Epoch: 0118 train_loss= 0.7743 train_acc= 1.0000 val_loss= 0.7743 val_acc= 1.0000 time= 0.0202\n",
      "Epoch: 0119 train_loss= 0.7734 train_acc= 1.0000 val_loss= 0.7734 val_acc= 1.0000 time= 0.0232\n",
      "Epoch: 0120 train_loss= 0.7719 train_acc= 1.0000 val_loss= 0.7719 val_acc= 1.0000 time= 0.0183\n",
      "Epoch: 0121 train_loss= 0.7699 train_acc= 1.0000 val_loss= 0.7699 val_acc= 1.0000 time= 0.0192\n",
      "Epoch: 0122 train_loss= 0.7676 train_acc= 1.0000 val_loss= 0.7676 val_acc= 1.0000 time= 0.0200\n",
      "Epoch: 0123 train_loss= 0.7655 train_acc= 1.0000 val_loss= 0.7655 val_acc= 1.0000 time= 0.0194\n",
      "Epoch: 0124 train_loss= 0.7639 train_acc= 1.0000 val_loss= 0.7639 val_acc= 1.0000 time= 0.0204\n",
      "Epoch: 0125 train_loss= 0.7628 train_acc= 1.0000 val_loss= 0.7628 val_acc= 1.0000 time= 0.0188\n",
      "Epoch: 0126 train_loss= 0.7620 train_acc= 1.0000 val_loss= 0.7620 val_acc= 1.0000 time= 0.0173\n",
      "Epoch: 0127 train_loss= 0.7605 train_acc= 1.0000 val_loss= 0.7605 val_acc= 1.0000 time= 0.0168\n",
      "Epoch: 0128 train_loss= 0.7585 train_acc= 1.0000 val_loss= 0.7585 val_acc= 1.0000 time= 0.0193\n",
      "Epoch: 0129 train_loss= 0.7559 train_acc= 1.0000 val_loss= 0.7559 val_acc= 1.0000 time= 0.0192\n",
      "Epoch: 0130 train_loss= 0.7533 train_acc= 1.0000 val_loss= 0.7533 val_acc= 1.0000 time= 0.0183\n",
      "Epoch: 0131 train_loss= 0.7509 train_acc= 1.0000 val_loss= 0.7509 val_acc= 1.0000 time= 0.0190\n",
      "Epoch: 0132 train_loss= 0.7494 train_acc= 1.0000 val_loss= 0.7494 val_acc= 1.0000 time= 0.0218\n",
      "Epoch: 0133 train_loss= 0.7489 train_acc= 1.0000 val_loss= 0.7489 val_acc= 1.0000 time= 0.0204\n",
      "Epoch: 0134 train_loss= 0.7489 train_acc= 1.0000 val_loss= 0.7489 val_acc= 1.0000 time= 0.0201\n",
      "Epoch: 0135 train_loss= 0.7488 train_acc= 1.0000 val_loss= 0.7488 val_acc= 1.0000 time= 0.0239\n",
      "Epoch: 0136 train_loss= 0.7481 train_acc= 1.0000 val_loss= 0.7481 val_acc= 1.0000 time= 0.0173\n",
      "Epoch: 0137 train_loss= 0.7465 train_acc= 1.0000 val_loss= 0.7465 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0138 train_loss= 0.7444 train_acc= 1.0000 val_loss= 0.7444 val_acc= 1.0000 time= 0.0170\n",
      "Epoch: 0139 train_loss= 0.7418 train_acc= 1.0000 val_loss= 0.7418 val_acc= 1.0000 time= 0.0132\n",
      "Epoch: 0140 train_loss= 0.7389 train_acc= 1.0000 val_loss= 0.7389 val_acc= 1.0000 time= 0.0152\n",
      "Epoch: 0141 train_loss= 0.7368 train_acc= 1.0000 val_loss= 0.7368 val_acc= 1.0000 time= 0.0130\n",
      "Epoch: 0142 train_loss= 0.7357 train_acc= 1.0000 val_loss= 0.7357 val_acc= 1.0000 time= 0.0136\n",
      "Epoch: 0143 train_loss= 0.7353 train_acc= 1.0000 val_loss= 0.7353 val_acc= 1.0000 time= 0.0127\n",
      "Epoch: 0144 train_loss= 0.7347 train_acc= 1.0000 val_loss= 0.7347 val_acc= 1.0000 time= 0.0143\n",
      "Epoch: 0145 train_loss= 0.7335 train_acc= 1.0000 val_loss= 0.7335 val_acc= 1.0000 time= 0.0116\n",
      "Epoch: 0146 train_loss= 0.7319 train_acc= 1.0000 val_loss= 0.7319 val_acc= 1.0000 time= 0.0104\n",
      "Epoch: 0147 train_loss= 0.7298 train_acc= 1.0000 val_loss= 0.7298 val_acc= 1.0000 time= 0.0116\n",
      "Epoch: 0148 train_loss= 0.7274 train_acc= 1.0000 val_loss= 0.7274 val_acc= 1.0000 time= 0.0108\n",
      "Epoch: 0149 train_loss= 0.7258 train_acc= 1.0000 val_loss= 0.7258 val_acc= 1.0000 time= 0.0108\n",
      "Epoch: 0150 train_loss= 0.7249 train_acc= 1.0000 val_loss= 0.7249 val_acc= 1.0000 time= 0.0602\n",
      "Epoch: 0151 train_loss= 0.7245 train_acc= 1.0000 val_loss= 0.7245 val_acc= 1.0000 time= 0.0253\n",
      "Epoch: 0152 train_loss= 0.7244 train_acc= 1.0000 val_loss= 0.7244 val_acc= 1.0000 time= 0.0258\n",
      "Epoch: 0153 train_loss= 0.7236 train_acc= 1.0000 val_loss= 0.7236 val_acc= 1.0000 time= 0.0162\n",
      "Epoch: 0154 train_loss= 0.7221 train_acc= 1.0000 val_loss= 0.7221 val_acc= 1.0000 time= 0.0184\n",
      "Epoch: 0155 train_loss= 0.7199 train_acc= 1.0000 val_loss= 0.7199 val_acc= 1.0000 time= 0.0188\n",
      "Epoch: 0156 train_loss= 0.7175 train_acc= 1.0000 val_loss= 0.7175 val_acc= 1.0000 time= 0.0188\n",
      "Epoch: 0157 train_loss= 0.7159 train_acc= 1.0000 val_loss= 0.7159 val_acc= 1.0000 time= 0.0213\n",
      "Epoch: 0158 train_loss= 0.7150 train_acc= 1.0000 val_loss= 0.7150 val_acc= 1.0000 time= 0.0194\n",
      "Epoch: 0159 train_loss= 0.7143 train_acc= 1.0000 val_loss= 0.7143 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0160 train_loss= 0.7135 train_acc= 1.0000 val_loss= 0.7135 val_acc= 1.0000 time= 0.0178\n",
      "Epoch: 0161 train_loss= 0.7127 train_acc= 1.0000 val_loss= 0.7127 val_acc= 1.0000 time= 0.0208\n",
      "Epoch: 0162 train_loss= 0.7116 train_acc= 1.0000 val_loss= 0.7116 val_acc= 1.0000 time= 0.0213\n",
      "Epoch: 0163 train_loss= 0.7108 train_acc= 1.0000 val_loss= 0.7108 val_acc= 1.0000 time= 0.0313\n",
      "Epoch: 0164 train_loss= 0.7099 train_acc= 1.0000 val_loss= 0.7099 val_acc= 1.0000 time= 0.0271\n",
      "Epoch: 0165 train_loss= 0.7091 train_acc= 1.0000 val_loss= 0.7091 val_acc= 1.0000 time= 0.0273\n",
      "Epoch: 0166 train_loss= 0.7081 train_acc= 1.0000 val_loss= 0.7081 val_acc= 1.0000 time= 0.0260\n",
      "Epoch: 0167 train_loss= 0.7068 train_acc= 1.0000 val_loss= 0.7068 val_acc= 1.0000 time= 0.0235\n",
      "Epoch: 0168 train_loss= 0.7053 train_acc= 1.0000 val_loss= 0.7053 val_acc= 1.0000 time= 0.0190\n",
      "Epoch: 0169 train_loss= 0.7038 train_acc= 1.0000 val_loss= 0.7038 val_acc= 1.0000 time= 0.0197\n",
      "Epoch: 0170 train_loss= 0.7026 train_acc= 1.0000 val_loss= 0.7026 val_acc= 1.0000 time= 0.0174\n",
      "Epoch: 0171 train_loss= 0.7017 train_acc= 1.0000 val_loss= 0.7017 val_acc= 1.0000 time= 0.0209\n",
      "Epoch: 0172 train_loss= 0.7014 train_acc= 1.0000 val_loss= 0.7014 val_acc= 1.0000 time= 0.0204\n",
      "Epoch: 0173 train_loss= 0.7014 train_acc= 1.0000 val_loss= 0.7014 val_acc= 1.0000 time= 0.0166\n",
      "Epoch: 0174 train_loss= 0.7013 train_acc= 1.0000 val_loss= 0.7013 val_acc= 1.0000 time= 0.0163\n",
      "Epoch: 0175 train_loss= 0.7006 train_acc= 1.0000 val_loss= 0.7006 val_acc= 1.0000 time= 0.0230\n",
      "Epoch: 0176 train_loss= 0.6995 train_acc= 1.0000 val_loss= 0.6995 val_acc= 1.0000 time= 0.0256\n",
      "Epoch: 0177 train_loss= 0.6981 train_acc= 1.0000 val_loss= 0.6981 val_acc= 1.0000 time= 0.0211\n",
      "Epoch: 0178 train_loss= 0.6964 train_acc= 1.0000 val_loss= 0.6964 val_acc= 1.0000 time= 0.0191\n",
      "Epoch: 0179 train_loss= 0.6951 train_acc= 1.0000 val_loss= 0.6951 val_acc= 1.0000 time= 0.0153\n",
      "Epoch: 0180 train_loss= 0.6942 train_acc= 1.0000 val_loss= 0.6942 val_acc= 1.0000 time= 0.0154\n",
      "Epoch: 0181 train_loss= 0.6934 train_acc= 1.0000 val_loss= 0.6934 val_acc= 1.0000 time= 0.0153\n",
      "Epoch: 0182 train_loss= 0.6925 train_acc= 1.0000 val_loss= 0.6925 val_acc= 1.0000 time= 0.0258\n",
      "Epoch: 0183 train_loss= 0.6917 train_acc= 1.0000 val_loss= 0.6917 val_acc= 1.0000 time= 0.0183\n",
      "Epoch: 0184 train_loss= 0.6913 train_acc= 1.0000 val_loss= 0.6913 val_acc= 1.0000 time= 0.0171\n",
      "Epoch: 0185 train_loss= 0.6911 train_acc= 1.0000 val_loss= 0.6911 val_acc= 1.0000 time= 0.0103\n",
      "Epoch: 0186 train_loss= 0.6906 train_acc= 1.0000 val_loss= 0.6906 val_acc= 1.0000 time= 0.0116\n",
      "Epoch: 0187 train_loss= 0.6897 train_acc= 1.0000 val_loss= 0.6897 val_acc= 1.0000 time= 0.0154\n",
      "Epoch: 0188 train_loss= 0.6884 train_acc= 1.0000 val_loss= 0.6884 val_acc= 1.0000 time= 0.0133\n",
      "Epoch: 0189 train_loss= 0.6869 train_acc= 1.0000 val_loss= 0.6869 val_acc= 1.0000 time= 0.0263\n",
      "Epoch: 0190 train_loss= 0.6859 train_acc= 1.0000 val_loss= 0.6859 val_acc= 1.0000 time= 0.0103\n",
      "Epoch: 0191 train_loss= 0.6853 train_acc= 1.0000 val_loss= 0.6853 val_acc= 1.0000 time= 0.0117\n",
      "Epoch: 0192 train_loss= 0.6851 train_acc= 1.0000 val_loss= 0.6851 val_acc= 1.0000 time= 0.0134\n",
      "Epoch: 0193 train_loss= 0.6846 train_acc= 1.0000 val_loss= 0.6846 val_acc= 1.0000 time= 0.0145\n",
      "Epoch: 0194 train_loss= 0.6838 train_acc= 1.0000 val_loss= 0.6838 val_acc= 1.0000 time= 0.0118\n",
      "Epoch: 0195 train_loss= 0.6829 train_acc= 1.0000 val_loss= 0.6829 val_acc= 1.0000 time= 0.0118\n",
      "Epoch: 0196 train_loss= 0.6818 train_acc= 1.0000 val_loss= 0.6818 val_acc= 1.0000 time= 0.0119\n",
      "Epoch: 0197 train_loss= 0.6808 train_acc= 1.0000 val_loss= 0.6808 val_acc= 1.0000 time= 0.0122\n",
      "Epoch: 0198 train_loss= 0.6797 train_acc= 1.0000 val_loss= 0.6797 val_acc= 1.0000 time= 0.0135\n",
      "Epoch: 0199 train_loss= 0.6792 train_acc= 1.0000 val_loss= 0.6792 val_acc= 1.0000 time= 0.0127\n",
      "Epoch: 0200 train_loss= 0.6791 train_acc= 1.0000 val_loss= 0.6791 val_acc= 1.0000 time= 0.0137\n",
      "Epoch: 0201 train_loss= 0.6788 train_acc= 1.0000 val_loss= 0.6788 val_acc= 1.0000 time= 0.0128\n",
      "Epoch: 0202 train_loss= 0.6784 train_acc= 1.0000 val_loss= 0.6784 val_acc= 1.0000 time= 0.0124\n",
      "Epoch: 0203 train_loss= 0.6776 train_acc= 1.0000 val_loss= 0.6776 val_acc= 1.0000 time= 0.0121\n",
      "Epoch: 0204 train_loss= 0.6767 train_acc= 1.0000 val_loss= 0.6767 val_acc= 1.0000 time= 0.0140\n",
      "Epoch: 0205 train_loss= 0.6760 train_acc= 1.0000 val_loss= 0.6760 val_acc= 1.0000 time= 0.0142\n",
      "Epoch: 0206 train_loss= 0.6755 train_acc= 1.0000 val_loss= 0.6755 val_acc= 1.0000 time= 0.0121\n",
      "Epoch: 0207 train_loss= 0.6749 train_acc= 1.0000 val_loss= 0.6749 val_acc= 1.0000 time= 0.0163\n",
      "Epoch: 0208 train_loss= 0.6742 train_acc= 1.0000 val_loss= 0.6742 val_acc= 1.0000 time= 0.0189\n",
      "Epoch: 0209 train_loss= 0.6734 train_acc= 1.0000 val_loss= 0.6734 val_acc= 1.0000 time= 0.0179\n",
      "Epoch: 0210 train_loss= 0.6726 train_acc= 1.0000 val_loss= 0.6726 val_acc= 1.0000 time= 0.0105\n",
      "Epoch: 0211 train_loss= 0.6720 train_acc= 1.0000 val_loss= 0.6720 val_acc= 1.0000 time= 0.0129\n",
      "Epoch: 0212 train_loss= 0.6715 train_acc= 1.0000 val_loss= 0.6715 val_acc= 1.0000 time= 0.0131\n",
      "Epoch: 0213 train_loss= 0.6708 train_acc= 1.0000 val_loss= 0.6708 val_acc= 1.0000 time= 0.0140\n",
      "Epoch: 0214 train_loss= 0.6702 train_acc= 1.0000 val_loss= 0.6702 val_acc= 1.0000 time= 0.0132\n",
      "Epoch: 0215 train_loss= 0.6699 train_acc= 1.0000 val_loss= 0.6699 val_acc= 1.0000 time= 0.0275\n",
      "Epoch: 0216 train_loss= 0.6696 train_acc= 1.0000 val_loss= 0.6696 val_acc= 1.0000 time= 0.0184\n",
      "Epoch: 0217 train_loss= 0.6691 train_acc= 1.0000 val_loss= 0.6691 val_acc= 1.0000 time= 0.0168\n",
      "Epoch: 0218 train_loss= 0.6684 train_acc= 1.0000 val_loss= 0.6684 val_acc= 1.0000 time= 0.0170\n",
      "Epoch: 0219 train_loss= 0.6677 train_acc= 1.0000 val_loss= 0.6677 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0220 train_loss= 0.6672 train_acc= 1.0000 val_loss= 0.6672 val_acc= 1.0000 time= 0.0166\n",
      "Epoch: 0221 train_loss= 0.6667 train_acc= 1.0000 val_loss= 0.6667 val_acc= 1.0000 time= 0.0173\n",
      "Epoch: 0222 train_loss= 0.6662 train_acc= 1.0000 val_loss= 0.6662 val_acc= 1.0000 time= 0.0175\n",
      "Epoch: 0223 train_loss= 0.6658 train_acc= 1.0000 val_loss= 0.6658 val_acc= 1.0000 time= 0.0173\n",
      "Epoch: 0224 train_loss= 0.6654 train_acc= 1.0000 val_loss= 0.6654 val_acc= 1.0000 time= 0.0177\n",
      "Epoch: 0225 train_loss= 0.6649 train_acc= 1.0000 val_loss= 0.6649 val_acc= 1.0000 time= 0.0171\n",
      "Epoch: 0226 train_loss= 0.6642 train_acc= 1.0000 val_loss= 0.6642 val_acc= 1.0000 time= 0.0173\n",
      "Epoch: 0227 train_loss= 0.6634 train_acc= 1.0000 val_loss= 0.6634 val_acc= 1.0000 time= 0.0202\n",
      "Epoch: 0228 train_loss= 0.6627 train_acc= 1.0000 val_loss= 0.6627 val_acc= 1.0000 time= 0.0174\n",
      "Epoch: 0229 train_loss= 0.6621 train_acc= 1.0000 val_loss= 0.6621 val_acc= 1.0000 time= 0.0203\n",
      "Epoch: 0230 train_loss= 0.6618 train_acc= 1.0000 val_loss= 0.6618 val_acc= 1.0000 time= 0.0095\n",
      "Epoch: 0231 train_loss= 0.6615 train_acc= 1.0000 val_loss= 0.6615 val_acc= 1.0000 time= 0.0121\n",
      "Epoch: 0232 train_loss= 0.6612 train_acc= 1.0000 val_loss= 0.6612 val_acc= 1.0000 time= 0.0122\n",
      "Epoch: 0233 train_loss= 0.6608 train_acc= 1.0000 val_loss= 0.6608 val_acc= 1.0000 time= 0.0137\n",
      "Epoch: 0234 train_loss= 0.6604 train_acc= 1.0000 val_loss= 0.6604 val_acc= 1.0000 time= 0.0141\n",
      "Epoch: 0235 train_loss= 0.6598 train_acc= 1.0000 val_loss= 0.6598 val_acc= 1.0000 time= 0.0124\n",
      "Epoch: 0236 train_loss= 0.6591 train_acc= 1.0000 val_loss= 0.6591 val_acc= 1.0000 time= 0.0143\n",
      "Epoch: 0237 train_loss= 0.6585 train_acc= 1.0000 val_loss= 0.6585 val_acc= 1.0000 time= 0.0130\n",
      "Epoch: 0238 train_loss= 0.6579 train_acc= 1.0000 val_loss= 0.6579 val_acc= 1.0000 time= 0.0126\n",
      "Epoch: 0239 train_loss= 0.6576 train_acc= 1.0000 val_loss= 0.6576 val_acc= 1.0000 time= 0.0128\n",
      "Epoch: 0240 train_loss= 0.6574 train_acc= 1.0000 val_loss= 0.6574 val_acc= 1.0000 time= 0.0130\n",
      "Epoch: 0241 train_loss= 0.6571 train_acc= 1.0000 val_loss= 0.6571 val_acc= 1.0000 time= 0.0124\n",
      "Epoch: 0242 train_loss= 0.6568 train_acc= 1.0000 val_loss= 0.6568 val_acc= 1.0000 time= 0.0130\n",
      "Epoch: 0243 train_loss= 0.6564 train_acc= 1.0000 val_loss= 0.6564 val_acc= 1.0000 time= 0.0170\n",
      "Epoch: 0244 train_loss= 0.6561 train_acc= 1.0000 val_loss= 0.6561 val_acc= 1.0000 time= 0.0144\n",
      "Epoch: 0245 train_loss= 0.6558 train_acc= 1.0000 val_loss= 0.6558 val_acc= 1.0000 time= 0.0159\n",
      "Epoch: 0246 train_loss= 0.6553 train_acc= 1.0000 val_loss= 0.6553 val_acc= 1.0000 time= 0.0314\n",
      "Epoch: 0247 train_loss= 0.6550 train_acc= 1.0000 val_loss= 0.6550 val_acc= 1.0000 time= 0.0111\n",
      "Epoch: 0248 train_loss= 0.6547 train_acc= 1.0000 val_loss= 0.6547 val_acc= 1.0000 time= 0.0146\n",
      "Epoch: 0249 train_loss= 0.6543 train_acc= 1.0000 val_loss= 0.6543 val_acc= 1.0000 time= 0.0140\n",
      "Epoch: 0250 train_loss= 0.6538 train_acc= 1.0000 val_loss= 0.6538 val_acc= 1.0000 time= 0.0133\n",
      "Epoch: 0251 train_loss= 0.6535 train_acc= 1.0000 val_loss= 0.6535 val_acc= 1.0000 time= 0.0258\n",
      "Epoch: 0252 train_loss= 0.6533 train_acc= 1.0000 val_loss= 0.6533 val_acc= 1.0000 time= 0.0200\n",
      "Epoch: 0253 train_loss= 0.6530 train_acc= 1.0000 val_loss= 0.6530 val_acc= 1.0000 time= 0.0199\n",
      "Epoch: 0254 train_loss= 0.6527 train_acc= 1.0000 val_loss= 0.6527 val_acc= 1.0000 time= 0.0217\n",
      "Epoch: 0255 train_loss= 0.6524 train_acc= 1.0000 val_loss= 0.6524 val_acc= 1.0000 time= 0.0189\n",
      "Epoch: 0256 train_loss= 0.6521 train_acc= 1.0000 val_loss= 0.6521 val_acc= 1.0000 time= 0.0154\n",
      "Epoch: 0257 train_loss= 0.6519 train_acc= 1.0000 val_loss= 0.6519 val_acc= 1.0000 time= 0.0177\n",
      "Epoch: 0258 train_loss= 0.6515 train_acc= 1.0000 val_loss= 0.6515 val_acc= 1.0000 time= 0.0182\n",
      "Epoch: 0259 train_loss= 0.6511 train_acc= 1.0000 val_loss= 0.6511 val_acc= 1.0000 time= 0.0178\n",
      "Epoch: 0260 train_loss= 0.6506 train_acc= 1.0000 val_loss= 0.6506 val_acc= 1.0000 time= 0.0172\n",
      "Epoch: 0261 train_loss= 0.6501 train_acc= 1.0000 val_loss= 0.6501 val_acc= 1.0000 time= 0.0166\n",
      "Epoch: 0262 train_loss= 0.6497 train_acc= 1.0000 val_loss= 0.6497 val_acc= 1.0000 time= 0.0192\n",
      "Epoch: 0263 train_loss= 0.6493 train_acc= 1.0000 val_loss= 0.6493 val_acc= 1.0000 time= 0.0195\n",
      "Epoch: 0264 train_loss= 0.6490 train_acc= 1.0000 val_loss= 0.6490 val_acc= 1.0000 time= 0.0183\n",
      "Epoch: 0265 train_loss= 0.6487 train_acc= 1.0000 val_loss= 0.6487 val_acc= 1.0000 time= 0.0214\n",
      "Epoch: 0266 train_loss= 0.6489 train_acc= 1.0000 val_loss= 0.6489 val_acc= 1.0000 time= 0.0181\n",
      "Epoch: 0267 train_loss= 0.6492 train_acc= 1.0000 val_loss= 0.6492 val_acc= 1.0000 time= 0.0222\n",
      "Epoch: 0268 train_loss= 0.6494 train_acc= 1.0000 val_loss= 0.6494 val_acc= 1.0000 time= 0.0194\n",
      "Epoch: 0269 train_loss= 0.6492 train_acc= 1.0000 val_loss= 0.6492 val_acc= 1.0000 time= 0.0217\n",
      "Epoch: 0270 train_loss= 0.6487 train_acc= 1.0000 val_loss= 0.6487 val_acc= 1.0000 time= 0.0262\n",
      "Epoch: 0271 train_loss= 0.6480 train_acc= 1.0000 val_loss= 0.6480 val_acc= 1.0000 time= 0.0251\n",
      "Epoch: 0272 train_loss= 0.6473 train_acc= 1.0000 val_loss= 0.6473 val_acc= 1.0000 time= 0.0221\n",
      "Epoch: 0273 train_loss= 0.6468 train_acc= 1.0000 val_loss= 0.6468 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0274 train_loss= 0.6465 train_acc= 1.0000 val_loss= 0.6465 val_acc= 1.0000 time= 0.0223\n",
      "Epoch: 0275 train_loss= 0.6466 train_acc= 1.0000 val_loss= 0.6466 val_acc= 1.0000 time= 0.0192\n",
      "Epoch: 0276 train_loss= 0.6465 train_acc= 1.0000 val_loss= 0.6465 val_acc= 1.0000 time= 0.0235\n",
      "Epoch: 0277 train_loss= 0.6463 train_acc= 1.0000 val_loss= 0.6463 val_acc= 1.0000 time= 0.0222\n",
      "Epoch: 0278 train_loss= 0.6459 train_acc= 1.0000 val_loss= 0.6459 val_acc= 1.0000 time= 0.0267\n",
      "Epoch: 0279 train_loss= 0.6456 train_acc= 1.0000 val_loss= 0.6456 val_acc= 1.0000 time= 0.0267\n",
      "Epoch: 0280 train_loss= 0.6453 train_acc= 1.0000 val_loss= 0.6453 val_acc= 1.0000 time= 0.0238\n",
      "Epoch: 0281 train_loss= 0.6449 train_acc= 1.0000 val_loss= 0.6449 val_acc= 1.0000 time= 0.0223\n",
      "Epoch: 0282 train_loss= 0.6445 train_acc= 1.0000 val_loss= 0.6445 val_acc= 1.0000 time= 0.0187\n",
      "Epoch: 0283 train_loss= 0.6443 train_acc= 1.0000 val_loss= 0.6443 val_acc= 1.0000 time= 0.0165\n",
      "Epoch: 0284 train_loss= 0.6440 train_acc= 1.0000 val_loss= 0.6440 val_acc= 1.0000 time= 0.0171\n",
      "Epoch: 0285 train_loss= 0.6436 train_acc= 1.0000 val_loss= 0.6436 val_acc= 1.0000 time= 0.0167\n",
      "Epoch: 0286 train_loss= 0.6432 train_acc= 1.0000 val_loss= 0.6432 val_acc= 1.0000 time= 0.0184\n",
      "Epoch: 0287 train_loss= 0.6427 train_acc= 1.0000 val_loss= 0.6427 val_acc= 1.0000 time= 0.0191\n",
      "Epoch: 0288 train_loss= 0.6423 train_acc= 1.0000 val_loss= 0.6423 val_acc= 1.0000 time= 0.0205\n",
      "Epoch: 0289 train_loss= 0.6420 train_acc= 1.0000 val_loss= 0.6420 val_acc= 1.0000 time= 0.0324\n",
      "Epoch: 0290 train_loss= 0.6420 train_acc= 1.0000 val_loss= 0.6420 val_acc= 1.0000 time= 0.0238\n",
      "Epoch: 0291 train_loss= 0.6420 train_acc= 1.0000 val_loss= 0.6420 val_acc= 1.0000 time= 0.0188\n",
      "Epoch: 0292 train_loss= 0.6419 train_acc= 1.0000 val_loss= 0.6419 val_acc= 1.0000 time= 0.0182\n",
      "Epoch: 0293 train_loss= 0.6417 train_acc= 1.0000 val_loss= 0.6417 val_acc= 1.0000 time= 0.0194\n",
      "Epoch: 0294 train_loss= 0.6413 train_acc= 1.0000 val_loss= 0.6413 val_acc= 1.0000 time= 0.0192\n",
      "Epoch: 0295 train_loss= 0.6410 train_acc= 1.0000 val_loss= 0.6410 val_acc= 1.0000 time= 0.0214\n",
      "Epoch: 0296 train_loss= 0.6406 train_acc= 1.0000 val_loss= 0.6406 val_acc= 1.0000 time= 0.0219\n",
      "Epoch: 0297 train_loss= 0.6402 train_acc= 1.0000 val_loss= 0.6402 val_acc= 1.0000 time= 0.0198\n",
      "Epoch: 0298 train_loss= 0.6399 train_acc= 1.0000 val_loss= 0.6399 val_acc= 1.0000 time= 0.0217\n",
      "Epoch: 0299 train_loss= 0.6397 train_acc= 1.0000 val_loss= 0.6397 val_acc= 1.0000 time= 0.0204\n",
      "Epoch: 0300 train_loss= 0.6394 train_acc= 1.0000 val_loss= 0.6394 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0301 train_loss= 0.6389 train_acc= 1.0000 val_loss= 0.6389 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0302 train_loss= 0.6386 train_acc= 1.0000 val_loss= 0.6386 val_acc= 1.0000 time= 0.0221\n",
      "Epoch: 0303 train_loss= 0.6385 train_acc= 1.0000 val_loss= 0.6385 val_acc= 1.0000 time= 0.0213\n",
      "Epoch: 0304 train_loss= 0.6385 train_acc= 1.0000 val_loss= 0.6385 val_acc= 1.0000 time= 0.0217\n",
      "Epoch: 0305 train_loss= 0.6384 train_acc= 1.0000 val_loss= 0.6384 val_acc= 1.0000 time= 0.0239\n",
      "Epoch: 0306 train_loss= 0.6382 train_acc= 1.0000 val_loss= 0.6382 val_acc= 1.0000 time= 0.0246\n",
      "Epoch: 0307 train_loss= 0.6380 train_acc= 1.0000 val_loss= 0.6380 val_acc= 1.0000 time= 0.0411\n",
      "Epoch: 0308 train_loss= 0.6376 train_acc= 1.0000 val_loss= 0.6376 val_acc= 1.0000 time= 0.0421\n",
      "Epoch: 0309 train_loss= 0.6372 train_acc= 1.0000 val_loss= 0.6372 val_acc= 1.0000 time= 0.0240\n",
      "Epoch: 0310 train_loss= 0.6368 train_acc= 1.0000 val_loss= 0.6368 val_acc= 1.0000 time= 0.0191\n",
      "Epoch: 0311 train_loss= 0.6364 train_acc= 1.0000 val_loss= 0.6364 val_acc= 1.0000 time= 0.0217\n",
      "Epoch: 0312 train_loss= 0.6359 train_acc= 1.0000 val_loss= 0.6359 val_acc= 1.0000 time= 0.0222\n",
      "Epoch: 0313 train_loss= 0.6357 train_acc= 1.0000 val_loss= 0.6357 val_acc= 1.0000 time= 0.0227\n",
      "Epoch: 0314 train_loss= 0.6356 train_acc= 1.0000 val_loss= 0.6356 val_acc= 1.0000 time= 0.0207\n",
      "Epoch: 0315 train_loss= 0.6356 train_acc= 1.0000 val_loss= 0.6356 val_acc= 1.0000 time= 0.0209\n",
      "Epoch: 0316 train_loss= 0.6355 train_acc= 1.0000 val_loss= 0.6355 val_acc= 1.0000 time= 0.0212\n",
      "Epoch: 0317 train_loss= 0.6352 train_acc= 1.0000 val_loss= 0.6352 val_acc= 1.0000 time= 0.0217\n",
      "Epoch: 0318 train_loss= 0.6348 train_acc= 1.0000 val_loss= 0.6348 val_acc= 1.0000 time= 0.0248\n",
      "Epoch: 0319 train_loss= 0.6344 train_acc= 1.0000 val_loss= 0.6344 val_acc= 1.0000 time= 0.0206\n",
      "Epoch: 0320 train_loss= 0.6341 train_acc= 1.0000 val_loss= 0.6341 val_acc= 1.0000 time= 0.0231\n",
      "Epoch: 0321 train_loss= 0.6339 train_acc= 1.0000 val_loss= 0.6339 val_acc= 1.0000 time= 0.0246\n",
      "Epoch: 0322 train_loss= 0.6339 train_acc= 1.0000 val_loss= 0.6339 val_acc= 1.0000 time= 0.0254\n",
      "Epoch: 0323 train_loss= 0.6339 train_acc= 1.0000 val_loss= 0.6339 val_acc= 1.0000 time= 0.0258\n",
      "Epoch: 0324 train_loss= 0.6337 train_acc= 1.0000 val_loss= 0.6337 val_acc= 1.0000 time= 0.0342\n",
      "Epoch: 0325 train_loss= 0.6333 train_acc= 1.0000 val_loss= 0.6333 val_acc= 1.0000 time= 0.0327\n",
      "Epoch: 0326 train_loss= 0.6327 train_acc= 1.0000 val_loss= 0.6327 val_acc= 1.0000 time= 0.0265\n",
      "Epoch: 0327 train_loss= 0.6323 train_acc= 1.0000 val_loss= 0.6323 val_acc= 1.0000 time= 0.0307\n",
      "Epoch: 0328 train_loss= 0.6322 train_acc= 1.0000 val_loss= 0.6322 val_acc= 1.0000 time= 0.0296\n",
      "Epoch: 0329 train_loss= 0.6323 train_acc= 1.0000 val_loss= 0.6323 val_acc= 1.0000 time= 0.0320\n",
      "Epoch: 0330 train_loss= 0.6324 train_acc= 1.0000 val_loss= 0.6324 val_acc= 1.0000 time= 0.0288\n",
      "Epoch: 0331 train_loss= 0.6325 train_acc= 1.0000 val_loss= 0.6325 val_acc= 1.0000 time= 0.0268\n",
      "Epoch: 0332 train_loss= 0.6323 train_acc= 1.0000 val_loss= 0.6323 val_acc= 1.0000 time= 0.0321\n",
      "Epoch: 0333 train_loss= 0.6319 train_acc= 1.0000 val_loss= 0.6319 val_acc= 1.0000 time= 0.0321\n",
      "Epoch: 0334 train_loss= 0.6312 train_acc= 1.0000 val_loss= 0.6312 val_acc= 1.0000 time= 0.0268\n",
      "Epoch: 0335 train_loss= 0.6308 train_acc= 1.0000 val_loss= 0.6308 val_acc= 1.0000 time= 0.0239\n",
      "Epoch: 0336 train_loss= 0.6307 train_acc= 1.0000 val_loss= 0.6307 val_acc= 1.0000 time= 0.0281\n",
      "Epoch: 0337 train_loss= 0.6308 train_acc= 1.0000 val_loss= 0.6308 val_acc= 1.0000 time= 0.0216\n",
      "Epoch: 0338 train_loss= 0.6309 train_acc= 1.0000 val_loss= 0.6309 val_acc= 1.0000 time= 0.0235\n",
      "Epoch: 0339 train_loss= 0.6308 train_acc= 1.0000 val_loss= 0.6308 val_acc= 1.0000 time= 0.0251\n",
      "Epoch: 0340 train_loss= 0.6304 train_acc= 1.0000 val_loss= 0.6304 val_acc= 1.0000 time= 0.0222\n",
      "Epoch: 0341 train_loss= 0.6299 train_acc= 1.0000 val_loss= 0.6299 val_acc= 1.0000 time= 0.0265\n",
      "Epoch: 0342 train_loss= 0.6293 train_acc= 1.0000 val_loss= 0.6293 val_acc= 1.0000 time= 0.0185\n",
      "Epoch: 0343 train_loss= 0.6288 train_acc= 1.0000 val_loss= 0.6288 val_acc= 1.0000 time= 0.0188\n",
      "Epoch: 0344 train_loss= 0.6283 train_acc= 1.0000 val_loss= 0.6283 val_acc= 1.0000 time= 0.0296\n",
      "Epoch: 0345 train_loss= 0.6281 train_acc= 1.0000 val_loss= 0.6281 val_acc= 1.0000 time= 0.0236\n",
      "Epoch: 0346 train_loss= 0.6282 train_acc= 1.0000 val_loss= 0.6282 val_acc= 1.0000 time= 0.0176\n",
      "Epoch: 0347 train_loss= 0.6284 train_acc= 1.0000 val_loss= 0.6284 val_acc= 1.0000 time= 0.0175\n",
      "Epoch: 0348 train_loss= 0.6284 train_acc= 1.0000 val_loss= 0.6284 val_acc= 1.0000 time= 0.0184\n",
      "Epoch: 0349 train_loss= 0.6282 train_acc= 1.0000 val_loss= 0.6282 val_acc= 1.0000 time= 0.0185\n",
      "Epoch: 0350 train_loss= 0.6276 train_acc= 1.0000 val_loss= 0.6276 val_acc= 1.0000 time= 0.0182\n",
      "Epoch: 0351 train_loss= 0.6270 train_acc= 1.0000 val_loss= 0.6270 val_acc= 1.0000 time= 0.0182\n",
      "Epoch: 0352 train_loss= 0.6265 train_acc= 1.0000 val_loss= 0.6265 val_acc= 1.0000 time= 0.0182\n",
      "Epoch: 0353 train_loss= 0.6264 train_acc= 1.0000 val_loss= 0.6264 val_acc= 1.0000 time= 0.0181\n",
      "Epoch: 0354 train_loss= 0.6265 train_acc= 1.0000 val_loss= 0.6265 val_acc= 1.0000 time= 0.0193\n",
      "Epoch: 0355 train_loss= 0.6265 train_acc= 1.0000 val_loss= 0.6265 val_acc= 1.0000 time= 0.0209\n",
      "Epoch: 0356 train_loss= 0.6261 train_acc= 1.0000 val_loss= 0.6261 val_acc= 1.0000 time= 0.0158\n",
      "Epoch: 0357 train_loss= 0.6256 train_acc= 1.0000 val_loss= 0.6256 val_acc= 1.0000 time= 0.0150\n",
      "Epoch: 0358 train_loss= 0.6252 train_acc= 1.0000 val_loss= 0.6252 val_acc= 1.0000 time= 0.0160\n",
      "Epoch: 0359 train_loss= 0.6248 train_acc= 1.0000 val_loss= 0.6248 val_acc= 1.0000 time= 0.0152\n",
      "Epoch: 0360 train_loss= 0.6245 train_acc= 1.0000 val_loss= 0.6245 val_acc= 1.0000 time= 0.0152\n",
      "Epoch: 0361 train_loss= 0.6242 train_acc= 1.0000 val_loss= 0.6242 val_acc= 1.0000 time= 0.0186\n",
      "Epoch: 0362 train_loss= 0.6240 train_acc= 1.0000 val_loss= 0.6240 val_acc= 1.0000 time= 0.0180\n",
      "Epoch: 0363 train_loss= 0.6237 train_acc= 1.0000 val_loss= 0.6237 val_acc= 1.0000 time= 0.0172\n",
      "Epoch: 0364 train_loss= 0.6234 train_acc= 1.0000 val_loss= 0.6234 val_acc= 1.0000 time= 0.0163\n",
      "Epoch: 0365 train_loss= 0.6231 train_acc= 1.0000 val_loss= 0.6231 val_acc= 1.0000 time= 0.0231\n",
      "Epoch: 0366 train_loss= 0.6227 train_acc= 1.0000 val_loss= 0.6227 val_acc= 1.0000 time= 0.0189\n",
      "Epoch: 0367 train_loss= 0.6222 train_acc= 1.0000 val_loss= 0.6222 val_acc= 1.0000 time= 0.0217\n",
      "Epoch: 0368 train_loss= 0.6219 train_acc= 1.0000 val_loss= 0.6219 val_acc= 1.0000 time= 0.0164\n",
      "Epoch: 0369 train_loss= 0.6214 train_acc= 1.0000 val_loss= 0.6214 val_acc= 1.0000 time= 0.0184\n",
      "Epoch: 0370 train_loss= 0.6212 train_acc= 1.0000 val_loss= 0.6212 val_acc= 1.0000 time= 0.0180\n",
      "Epoch: 0371 train_loss= 0.6211 train_acc= 1.0000 val_loss= 0.6211 val_acc= 1.0000 time= 0.0263\n",
      "Epoch: 0372 train_loss= 0.6212 train_acc= 1.0000 val_loss= 0.6212 val_acc= 1.0000 time= 0.0234\n",
      "Epoch: 0373 train_loss= 0.6212 train_acc= 1.0000 val_loss= 0.6212 val_acc= 1.0000 time= 0.0191\n",
      "Epoch: 0374 train_loss= 0.6210 train_acc= 1.0000 val_loss= 0.6210 val_acc= 1.0000 time= 0.0161\n",
      "Epoch: 0375 train_loss= 0.6204 train_acc= 1.0000 val_loss= 0.6204 val_acc= 1.0000 time= 0.0264\n",
      "Epoch: 0376 train_loss= 0.6197 train_acc= 1.0000 val_loss= 0.6197 val_acc= 1.0000 time= 0.0184\n",
      "Epoch: 0377 train_loss= 0.6192 train_acc= 1.0000 val_loss= 0.6192 val_acc= 1.0000 time= 0.0172\n",
      "Epoch: 0378 train_loss= 0.6189 train_acc= 1.0000 val_loss= 0.6189 val_acc= 1.0000 time= 0.0206\n",
      "Epoch: 0379 train_loss= 0.6188 train_acc= 1.0000 val_loss= 0.6188 val_acc= 1.0000 time= 0.0171\n",
      "Epoch: 0380 train_loss= 0.6187 train_acc= 1.0000 val_loss= 0.6187 val_acc= 1.0000 time= 0.0213\n",
      "Epoch: 0381 train_loss= 0.6184 train_acc= 1.0000 val_loss= 0.6184 val_acc= 1.0000 time= 0.0309\n",
      "Epoch: 0382 train_loss= 0.6179 train_acc= 1.0000 val_loss= 0.6179 val_acc= 1.0000 time= 0.0164\n",
      "Epoch: 0383 train_loss= 0.6173 train_acc= 1.0000 val_loss= 0.6173 val_acc= 1.0000 time= 0.0210\n",
      "Epoch: 0384 train_loss= 0.6169 train_acc= 1.0000 val_loss= 0.6169 val_acc= 1.0000 time= 0.0166\n",
      "Epoch: 0385 train_loss= 0.6167 train_acc= 1.0000 val_loss= 0.6167 val_acc= 1.0000 time= 0.0260\n",
      "Epoch: 0386 train_loss= 0.6168 train_acc= 1.0000 val_loss= 0.6168 val_acc= 1.0000 time= 0.0279\n",
      "Epoch: 0387 train_loss= 0.6168 train_acc= 1.0000 val_loss= 0.6168 val_acc= 1.0000 time= 0.0265\n",
      "Epoch: 0388 train_loss= 0.6168 train_acc= 1.0000 val_loss= 0.6168 val_acc= 1.0000 time= 0.0249\n",
      "Epoch: 0389 train_loss= 0.6164 train_acc= 1.0000 val_loss= 0.6164 val_acc= 1.0000 time= 0.0244\n",
      "Epoch: 0390 train_loss= 0.6158 train_acc= 1.0000 val_loss= 0.6158 val_acc= 1.0000 time= 0.0266\n",
      "Epoch: 0391 train_loss= 0.6151 train_acc= 1.0000 val_loss= 0.6151 val_acc= 1.0000 time= 0.0267\n",
      "Epoch: 0392 train_loss= 0.6147 train_acc= 1.0000 val_loss= 0.6147 val_acc= 1.0000 time= 0.0271\n",
      "Epoch: 0393 train_loss= 0.6150 train_acc= 1.0000 val_loss= 0.6150 val_acc= 1.0000 time= 0.0124\n",
      "Epoch: 0394 train_loss= 0.6155 train_acc= 1.0000 val_loss= 0.6155 val_acc= 1.0000 time= 0.0198\n",
      "Epoch: 0395 train_loss= 0.6158 train_acc= 1.0000 val_loss= 0.6158 val_acc= 1.0000 time= 0.0260\n",
      "Epoch: 0396 train_loss= 0.6153 train_acc= 1.0000 val_loss= 0.6153 val_acc= 1.0000 time= 0.0269\n",
      "Epoch: 0397 train_loss= 0.6144 train_acc= 1.0000 val_loss= 0.6144 val_acc= 1.0000 time= 0.0275\n",
      "Epoch: 0398 train_loss= 0.6132 train_acc= 1.0000 val_loss= 0.6132 val_acc= 1.0000 time= 0.0149\n",
      "Epoch: 0399 train_loss= 0.6120 train_acc= 1.0000 val_loss= 0.6120 val_acc= 1.0000 time= 0.0196\n",
      "Epoch: 0400 train_loss= 0.6114 train_acc= 1.0000 val_loss= 0.6114 val_acc= 1.0000 time= 0.0181\n",
      "Epoch: 0401 train_loss= 0.6118 train_acc= 1.0000 val_loss= 0.6118 val_acc= 1.0000 time= 0.0228\n",
      "Epoch: 0402 train_loss= 0.6127 train_acc= 1.0000 val_loss= 0.6127 val_acc= 1.0000 time= 0.0100\n",
      "Epoch: 0403 train_loss= 0.6134 train_acc= 1.0000 val_loss= 0.6134 val_acc= 1.0000 time= 0.0262\n",
      "Epoch: 0404 train_loss= 0.6131 train_acc= 1.0000 val_loss= 0.6131 val_acc= 1.0000 time= 0.0175\n",
      "Epoch: 0405 train_loss= 0.6120 train_acc= 1.0000 val_loss= 0.6120 val_acc= 1.0000 time= 0.0219\n",
      "Epoch: 0406 train_loss= 0.6107 train_acc= 1.0000 val_loss= 0.6107 val_acc= 1.0000 time= 0.0225\n",
      "Epoch: 0407 train_loss= 0.6095 train_acc= 1.0000 val_loss= 0.6095 val_acc= 1.0000 time= 0.0205\n",
      "Epoch: 0408 train_loss= 0.6089 train_acc= 1.0000 val_loss= 0.6089 val_acc= 1.0000 time= 0.0289\n",
      "Epoch: 0409 train_loss= 0.6090 train_acc= 1.0000 val_loss= 0.6090 val_acc= 1.0000 time= 0.0252\n",
      "Epoch: 0410 train_loss= 0.6095 train_acc= 1.0000 val_loss= 0.6095 val_acc= 1.0000 time= 0.0171\n",
      "Epoch: 0411 train_loss= 0.6100 train_acc= 1.0000 val_loss= 0.6100 val_acc= 1.0000 time= 0.0278\n",
      "Epoch: 0412 train_loss= 0.6101 train_acc= 1.0000 val_loss= 0.6101 val_acc= 1.0000 time= 0.0196\n",
      "Epoch: 0413 train_loss= 0.6093 train_acc= 1.0000 val_loss= 0.6093 val_acc= 1.0000 time= 0.0161\n",
      "Epoch: 0414 train_loss= 0.6081 train_acc= 1.0000 val_loss= 0.6081 val_acc= 1.0000 time= 0.0235\n",
      "Epoch: 0415 train_loss= 0.6073 train_acc= 1.0000 val_loss= 0.6073 val_acc= 1.0000 time= 0.0308\n",
      "Epoch: 0416 train_loss= 0.6073 train_acc= 1.0000 val_loss= 0.6073 val_acc= 1.0000 time= 0.0239\n",
      "Epoch: 0417 train_loss= 0.6078 train_acc= 1.0000 val_loss= 0.6078 val_acc= 1.0000 time= 0.0233\n",
      "Epoch: 0418 train_loss= 0.6083 train_acc= 1.0000 val_loss= 0.6083 val_acc= 1.0000 time= 0.0240\n",
      "Epoch: 0419 train_loss= 0.6083 train_acc= 1.0000 val_loss= 0.6083 val_acc= 1.0000 time= 0.0281\n",
      "Epoch: 0420 train_loss= 0.6074 train_acc= 1.0000 val_loss= 0.6074 val_acc= 1.0000 time= 0.0246\n",
      "Epoch: 0421 train_loss= 0.6062 train_acc= 1.0000 val_loss= 0.6062 val_acc= 1.0000 time= 0.0208\n",
      "Epoch: 0422 train_loss= 0.6052 train_acc= 1.0000 val_loss= 0.6052 val_acc= 1.0000 time= 0.0222\n",
      "Epoch: 0423 train_loss= 0.6053 train_acc= 1.0000 val_loss= 0.6053 val_acc= 1.0000 time= 0.0201\n",
      "Epoch: 0424 train_loss= 0.6058 train_acc= 1.0000 val_loss= 0.6058 val_acc= 1.0000 time= 0.0215\n",
      "Epoch: 0425 train_loss= 0.6064 train_acc= 1.0000 val_loss= 0.6064 val_acc= 1.0000 time= 0.0214\n",
      "Epoch: 0426 train_loss= 0.6066 train_acc= 1.0000 val_loss= 0.6066 val_acc= 1.0000 time= 0.0183\n",
      "Epoch: 0427 train_loss= 0.6060 train_acc= 1.0000 val_loss= 0.6060 val_acc= 1.0000 time= 0.0212\n",
      "Epoch: 0428 train_loss= 0.6050 train_acc= 1.0000 val_loss= 0.6050 val_acc= 1.0000 time= 0.0265\n",
      "Epoch: 0429 train_loss= 0.6037 train_acc= 1.0000 val_loss= 0.6037 val_acc= 1.0000 time= 0.0206\n",
      "Epoch: 0430 train_loss= 0.6029 train_acc= 1.0000 val_loss= 0.6029 val_acc= 1.0000 time= 0.0242\n",
      "Epoch: 0431 train_loss= 0.6029 train_acc= 1.0000 val_loss= 0.6029 val_acc= 1.0000 time= 0.0205\n",
      "Epoch: 0432 train_loss= 0.6036 train_acc= 1.0000 val_loss= 0.6036 val_acc= 1.0000 time= 0.0181\n",
      "Epoch: 0433 train_loss= 0.6043 train_acc= 1.0000 val_loss= 0.6043 val_acc= 1.0000 time= 0.0219\n",
      "Epoch: 0434 train_loss= 0.6045 train_acc= 1.0000 val_loss= 0.6045 val_acc= 1.0000 time= 0.0163\n",
      "Epoch: 0435 train_loss= 0.6037 train_acc= 1.0000 val_loss= 0.6037 val_acc= 1.0000 time= 0.0176\n",
      "Epoch: 0436 train_loss= 0.6021 train_acc= 1.0000 val_loss= 0.6021 val_acc= 1.0000 time= 0.0209\n",
      "Epoch: 0437 train_loss= 0.6007 train_acc= 1.0000 val_loss= 0.6007 val_acc= 1.0000 time= 0.0199\n",
      "Epoch: 0438 train_loss= 0.6008 train_acc= 1.0000 val_loss= 0.6008 val_acc= 1.0000 time= 0.0195\n",
      "Epoch: 0439 train_loss= 0.6020 train_acc= 1.0000 val_loss= 0.6020 val_acc= 1.0000 time= 0.0196\n",
      "Epoch: 0440 train_loss= 0.6027 train_acc= 1.0000 val_loss= 0.6027 val_acc= 1.0000 time= 0.0176\n",
      "Epoch: 0441 train_loss= 0.6024 train_acc= 1.0000 val_loss= 0.6024 val_acc= 1.0000 time= 0.0214\n",
      "Epoch: 0442 train_loss= 0.6016 train_acc= 1.0000 val_loss= 0.6016 val_acc= 1.0000 time= 0.0193\n",
      "Epoch: 0443 train_loss= 0.6007 train_acc= 1.0000 val_loss= 0.6007 val_acc= 1.0000 time= 0.0208\n",
      "Epoch: 0444 train_loss= 0.6002 train_acc= 1.0000 val_loss= 0.6002 val_acc= 1.0000 time= 0.0223\n",
      "Epoch: 0445 train_loss= 0.6002 train_acc= 1.0000 val_loss= 0.6002 val_acc= 1.0000 time= 0.0279\n",
      "Epoch: 0446 train_loss= 0.6001 train_acc= 1.0000 val_loss= 0.6001 val_acc= 1.0000 time= 0.0217\n",
      "Epoch: 0447 train_loss= 0.6000 train_acc= 1.0000 val_loss= 0.6000 val_acc= 1.0000 time= 0.0182\n",
      "Epoch: 0448 train_loss= 0.5996 train_acc= 1.0000 val_loss= 0.5996 val_acc= 1.0000 time= 0.0191\n",
      "Epoch: 0449 train_loss= 0.5991 train_acc= 1.0000 val_loss= 0.5991 val_acc= 1.0000 time= 0.0174\n",
      "Epoch: 0450 train_loss= 0.5991 train_acc= 1.0000 val_loss= 0.5991 val_acc= 1.0000 time= 0.0184\n",
      "Epoch: 0451 train_loss= 0.5994 train_acc= 1.0000 val_loss= 0.5994 val_acc= 1.0000 time= 0.0196\n",
      "Epoch: 0452 train_loss= 0.5997 train_acc= 1.0000 val_loss= 0.5997 val_acc= 1.0000 time= 0.0164\n",
      "Epoch: 0453 train_loss= 0.5996 train_acc= 1.0000 val_loss= 0.5996 val_acc= 1.0000 time= 0.0191\n",
      "Epoch: 0454 train_loss= 0.5989 train_acc= 1.0000 val_loss= 0.5989 val_acc= 1.0000 time= 0.0182\n",
      "Epoch: 0455 train_loss= 0.5973 train_acc= 1.0000 val_loss= 0.5973 val_acc= 1.0000 time= 0.0178\n",
      "Epoch: 0456 train_loss= 0.5959 train_acc= 1.0000 val_loss= 0.5959 val_acc= 1.0000 time= 0.0213\n",
      "Epoch: 0457 train_loss= 0.5959 train_acc= 1.0000 val_loss= 0.5959 val_acc= 1.0000 time= 0.0168\n",
      "Epoch: 0458 train_loss= 0.5972 train_acc= 1.0000 val_loss= 0.5972 val_acc= 1.0000 time= 0.0099\n",
      "Epoch: 0459 train_loss= 0.5987 train_acc= 1.0000 val_loss= 0.5987 val_acc= 1.0000 time= 0.0117\n",
      "Epoch: 0460 train_loss= 0.5991 train_acc= 1.0000 val_loss= 0.5991 val_acc= 1.0000 time= 0.0131\n",
      "Epoch: 0461 train_loss= 0.5982 train_acc= 1.0000 val_loss= 0.5982 val_acc= 1.0000 time= 0.0250\n",
      "Epoch: 0462 train_loss= 0.5962 train_acc= 1.0000 val_loss= 0.5962 val_acc= 1.0000 time= 0.0115\n",
      "Epoch: 0463 train_loss= 0.5948 train_acc= 1.0000 val_loss= 0.5948 val_acc= 1.0000 time= 0.0205\n",
      "Epoch: 0464 train_loss= 0.5942 train_acc= 1.0000 val_loss= 0.5942 val_acc= 1.0000 time= 0.0160\n",
      "Epoch: 0465 train_loss= 0.5943 train_acc= 1.0000 val_loss= 0.5943 val_acc= 1.0000 time= 0.0154\n",
      "Epoch: 0466 train_loss= 0.5949 train_acc= 1.0000 val_loss= 0.5949 val_acc= 1.0000 time= 0.0098\n",
      "Epoch: 0467 train_loss= 0.5954 train_acc= 1.0000 val_loss= 0.5954 val_acc= 1.0000 time= 0.0095\n",
      "Epoch: 0468 train_loss= 0.5953 train_acc= 1.0000 val_loss= 0.5953 val_acc= 1.0000 time= 0.0272\n",
      "Epoch: 0469 train_loss= 0.5951 train_acc= 1.0000 val_loss= 0.5951 val_acc= 1.0000 time= 0.0168\n",
      "Epoch: 0470 train_loss= 0.5947 train_acc= 1.0000 val_loss= 0.5947 val_acc= 1.0000 time= 0.0149\n",
      "Epoch: 0471 train_loss= 0.5944 train_acc= 1.0000 val_loss= 0.5944 val_acc= 1.0000 time= 0.0185\n",
      "Epoch: 0472 train_loss= 0.5942 train_acc= 1.0000 val_loss= 0.5942 val_acc= 1.0000 time= 0.0175\n",
      "Epoch: 0473 train_loss= 0.5940 train_acc= 1.0000 val_loss= 0.5940 val_acc= 1.0000 time= 0.0171\n",
      "Epoch: 0474 train_loss= 0.5934 train_acc= 1.0000 val_loss= 0.5934 val_acc= 1.0000 time= 0.0193\n",
      "Epoch: 0475 train_loss= 0.5925 train_acc= 1.0000 val_loss= 0.5925 val_acc= 1.0000 time= 0.0166\n",
      "Epoch: 0476 train_loss= 0.5921 train_acc= 1.0000 val_loss= 0.5921 val_acc= 1.0000 time= 0.0146\n",
      "Epoch: 0477 train_loss= 0.5920 train_acc= 1.0000 val_loss= 0.5920 val_acc= 1.0000 time= 0.0158\n",
      "Epoch: 0478 train_loss= 0.5921 train_acc= 1.0000 val_loss= 0.5921 val_acc= 1.0000 time= 0.0161\n",
      "Epoch: 0479 train_loss= 0.5927 train_acc= 1.0000 val_loss= 0.5927 val_acc= 1.0000 time= 0.0164\n",
      "Epoch: 0480 train_loss= 0.5932 train_acc= 1.0000 val_loss= 0.5932 val_acc= 1.0000 time= 0.0159\n",
      "Epoch: 0481 train_loss= 0.5930 train_acc= 1.0000 val_loss= 0.5930 val_acc= 1.0000 time= 0.0147\n",
      "Epoch: 0482 train_loss= 0.5917 train_acc= 1.0000 val_loss= 0.5917 val_acc= 1.0000 time= 0.0168\n",
      "Epoch: 0483 train_loss= 0.5902 train_acc= 1.0000 val_loss= 0.5902 val_acc= 1.0000 time= 0.0166\n",
      "Epoch: 0484 train_loss= 0.5898 train_acc= 1.0000 val_loss= 0.5898 val_acc= 1.0000 time= 0.0203\n",
      "Epoch: 0485 train_loss= 0.5902 train_acc= 1.0000 val_loss= 0.5902 val_acc= 1.0000 time= 0.0192\n",
      "Epoch: 0486 train_loss= 0.5907 train_acc= 1.0000 val_loss= 0.5907 val_acc= 1.0000 time= 0.0182\n",
      "Epoch: 0487 train_loss= 0.5912 train_acc= 1.0000 val_loss= 0.5912 val_acc= 1.0000 time= 0.0188\n",
      "Epoch: 0488 train_loss= 0.5912 train_acc= 1.0000 val_loss= 0.5912 val_acc= 1.0000 time= 0.0169\n",
      "Epoch: 0489 train_loss= 0.5897 train_acc= 1.0000 val_loss= 0.5897 val_acc= 1.0000 time= 0.0180\n",
      "Epoch: 0490 train_loss= 0.5884 train_acc= 1.0000 val_loss= 0.5884 val_acc= 1.0000 time= 0.0188\n",
      "Epoch: 0491 train_loss= 0.5885 train_acc= 1.0000 val_loss= 0.5885 val_acc= 1.0000 time= 0.0178\n",
      "Epoch: 0492 train_loss= 0.5898 train_acc= 1.0000 val_loss= 0.5898 val_acc= 1.0000 time= 0.0197\n",
      "Epoch: 0493 train_loss= 0.5904 train_acc= 1.0000 val_loss= 0.5904 val_acc= 1.0000 time= 0.0185\n",
      "Epoch: 0494 train_loss= 0.5897 train_acc= 1.0000 val_loss= 0.5897 val_acc= 1.0000 time= 0.0190\n",
      "Epoch: 0495 train_loss= 0.5889 train_acc= 1.0000 val_loss= 0.5889 val_acc= 1.0000 time= 0.0167\n",
      "Epoch: 0496 train_loss= 0.5885 train_acc= 1.0000 val_loss= 0.5885 val_acc= 1.0000 time= 0.0159\n",
      "Epoch: 0497 train_loss= 0.5887 train_acc= 1.0000 val_loss= 0.5887 val_acc= 1.0000 time= 0.0185\n",
      "Epoch: 0498 train_loss= 0.5884 train_acc= 1.0000 val_loss= 0.5884 val_acc= 1.0000 time= 0.0164\n",
      "Epoch: 0499 train_loss= 0.5879 train_acc= 1.0000 val_loss= 0.5879 val_acc= 1.0000 time= 0.0153\n",
      "Epoch: 0500 train_loss= 0.5877 train_acc= 1.0000 val_loss= 0.5877 val_acc= 1.0000 time= 0.0176\n",
      "Epoch: 0501 train_loss= 0.5881 train_acc= 1.0000 val_loss= 0.5881 val_acc= 1.0000 time= 0.0182\n",
      "Epoch: 0502 train_loss= 0.5885 train_acc= 1.0000 val_loss= 0.5885 val_acc= 1.0000 time= 0.0157\n",
      "Epoch: 0503 train_loss= 0.5883 train_acc= 1.0000 val_loss= 0.5883 val_acc= 1.0000 time= 0.0176\n",
      "Epoch: 0504 train_loss= 0.5872 train_acc= 1.0000 val_loss= 0.5872 val_acc= 1.0000 time= 0.0175\n",
      "Epoch: 0505 train_loss= 0.5859 train_acc= 1.0000 val_loss= 0.5859 val_acc= 1.0000 time= 0.0166\n",
      "Epoch: 0506 train_loss= 0.5855 train_acc= 1.0000 val_loss= 0.5855 val_acc= 1.0000 time= 0.0168\n",
      "Epoch: 0507 train_loss= 0.5864 train_acc= 1.0000 val_loss= 0.5864 val_acc= 1.0000 time= 0.0164\n",
      "Epoch: 0508 train_loss= 0.5876 train_acc= 1.0000 val_loss= 0.5876 val_acc= 1.0000 time= 0.0191\n",
      "Epoch: 0509 train_loss= 0.5875 train_acc= 1.0000 val_loss= 0.5875 val_acc= 1.0000 time= 0.0193\n",
      "Epoch: 0510 train_loss= 0.5863 train_acc= 1.0000 val_loss= 0.5863 val_acc= 1.0000 time= 0.0181\n",
      "Epoch: 0511 train_loss= 0.5847 train_acc= 1.0000 val_loss= 0.5847 val_acc= 1.0000 time= 0.0184\n",
      "Epoch: 0512 train_loss= 0.5839 train_acc= 1.0000 val_loss= 0.5839 val_acc= 1.0000 time= 0.0238\n",
      "Epoch: 0513 train_loss= 0.5843 train_acc= 1.0000 val_loss= 0.5843 val_acc= 1.0000 time= 0.0241\n",
      "Epoch: 0514 train_loss= 0.5856 train_acc= 1.0000 val_loss= 0.5856 val_acc= 1.0000 time= 0.0237\n",
      "Epoch: 0515 train_loss= 0.5866 train_acc= 1.0000 val_loss= 0.5866 val_acc= 1.0000 time= 0.0256\n",
      "Epoch: 0516 train_loss= 0.5856 train_acc= 1.0000 val_loss= 0.5856 val_acc= 1.0000 time= 0.0270\n",
      "Epoch: 0517 train_loss= 0.5834 train_acc= 1.0000 val_loss= 0.5834 val_acc= 1.0000 time= 0.0298\n",
      "Epoch: 0518 train_loss= 0.5827 train_acc= 1.0000 val_loss= 0.5827 val_acc= 1.0000 time= 0.0258\n",
      "Epoch: 0519 train_loss= 0.5836 train_acc= 1.0000 val_loss= 0.5836 val_acc= 1.0000 time= 0.0339\n",
      "Epoch: 0520 train_loss= 0.5841 train_acc= 1.0000 val_loss= 0.5841 val_acc= 1.0000 time= 0.0317\n",
      "Epoch: 0521 train_loss= 0.5839 train_acc= 1.0000 val_loss= 0.5839 val_acc= 1.0000 time= 0.0246\n",
      "Epoch: 0522 train_loss= 0.5836 train_acc= 1.0000 val_loss= 0.5836 val_acc= 1.0000 time= 0.0264\n",
      "Epoch: 0523 train_loss= 0.5834 train_acc= 1.0000 val_loss= 0.5834 val_acc= 1.0000 time= 0.0218\n",
      "Epoch: 0524 train_loss= 0.5832 train_acc= 1.0000 val_loss= 0.5832 val_acc= 1.0000 time= 0.0288\n",
      "Epoch: 0525 train_loss= 0.5826 train_acc= 1.0000 val_loss= 0.5826 val_acc= 1.0000 time= 0.0263\n",
      "Epoch: 0526 train_loss= 0.5818 train_acc= 1.0000 val_loss= 0.5818 val_acc= 1.0000 time= 0.0271\n",
      "Epoch: 0527 train_loss= 0.5809 train_acc= 1.0000 val_loss= 0.5809 val_acc= 1.0000 time= 0.0256\n",
      "Epoch: 0528 train_loss= 0.5809 train_acc= 1.0000 val_loss= 0.5809 val_acc= 1.0000 time= 0.0460\n",
      "Epoch: 0529 train_loss= 0.5821 train_acc= 1.0000 val_loss= 0.5821 val_acc= 1.0000 time= 0.0332\n",
      "Epoch: 0530 train_loss= 0.5833 train_acc= 1.0000 val_loss= 0.5833 val_acc= 1.0000 time= 0.0385\n",
      "Epoch: 0531 train_loss= 0.5834 train_acc= 1.0000 val_loss= 0.5834 val_acc= 1.0000 time= 0.0332\n",
      "Epoch: 0532 train_loss= 0.5813 train_acc= 1.0000 val_loss= 0.5813 val_acc= 1.0000 time= 0.0337\n",
      "Epoch: 0533 train_loss= 0.5787 train_acc= 1.0000 val_loss= 0.5787 val_acc= 1.0000 time= 0.0246\n",
      "Epoch: 0534 train_loss= 0.5781 train_acc= 1.0000 val_loss= 0.5781 val_acc= 1.0000 time= 0.0247\n",
      "Epoch: 0535 train_loss= 0.5796 train_acc= 1.0000 val_loss= 0.5796 val_acc= 1.0000 time= 0.0248\n",
      "Epoch: 0536 train_loss= 0.5819 train_acc= 1.0000 val_loss= 0.5819 val_acc= 1.0000 time= 0.0240\n",
      "Epoch: 0537 train_loss= 0.5824 train_acc= 1.0000 val_loss= 0.5824 val_acc= 1.0000 time= 0.0265\n",
      "Epoch: 0538 train_loss= 0.5809 train_acc= 1.0000 val_loss= 0.5809 val_acc= 1.0000 time= 0.0258\n",
      "Epoch: 0539 train_loss= 0.5783 train_acc= 1.0000 val_loss= 0.5783 val_acc= 1.0000 time= 0.0243\n",
      "Epoch: 0540 train_loss= 0.5771 train_acc= 1.0000 val_loss= 0.5771 val_acc= 1.0000 time= 0.0254\n",
      "Epoch: 0541 train_loss= 0.5781 train_acc= 1.0000 val_loss= 0.5781 val_acc= 1.0000 time= 0.0220\n",
      "Epoch: 0542 train_loss= 0.5801 train_acc= 1.0000 val_loss= 0.5801 val_acc= 1.0000 time= 0.0252\n",
      "Epoch: 0543 train_loss= 0.5805 train_acc= 1.0000 val_loss= 0.5805 val_acc= 1.0000 time= 0.0253\n",
      "Epoch: 0544 train_loss= 0.5787 train_acc= 1.0000 val_loss= 0.5787 val_acc= 1.0000 time= 0.0229\n",
      "Epoch: 0545 train_loss= 0.5765 train_acc= 1.0000 val_loss= 0.5765 val_acc= 1.0000 time= 0.0205\n",
      "Epoch: 0546 train_loss= 0.5765 train_acc= 1.0000 val_loss= 0.5765 val_acc= 1.0000 time= 0.0228\n",
      "Epoch: 0547 train_loss= 0.5786 train_acc= 1.0000 val_loss= 0.5786 val_acc= 1.0000 time= 0.0223\n",
      "Epoch: 0548 train_loss= 0.5798 train_acc= 1.0000 val_loss= 0.5798 val_acc= 1.0000 time= 0.0227\n",
      "Epoch: 0549 train_loss= 0.5790 train_acc= 1.0000 val_loss= 0.5790 val_acc= 1.0000 time= 0.0219\n",
      "Epoch: 0550 train_loss= 0.5767 train_acc= 1.0000 val_loss= 0.5767 val_acc= 1.0000 time= 0.0209\n",
      "Epoch: 0551 train_loss= 0.5747 train_acc= 1.0000 val_loss= 0.5747 val_acc= 1.0000 time= 0.0195\n",
      "Epoch: 0552 train_loss= 0.5752 train_acc= 1.0000 val_loss= 0.5752 val_acc= 1.0000 time= 0.0190\n",
      "Epoch: 0553 train_loss= 0.5769 train_acc= 1.0000 val_loss= 0.5769 val_acc= 1.0000 time= 0.0179\n",
      "Epoch: 0554 train_loss= 0.5778 train_acc= 1.0000 val_loss= 0.5778 val_acc= 1.0000 time= 0.0192\n",
      "Epoch: 0555 train_loss= 0.5776 train_acc= 1.0000 val_loss= 0.5776 val_acc= 1.0000 time= 0.0185\n",
      "Epoch: 0556 train_loss= 0.5764 train_acc= 1.0000 val_loss= 0.5764 val_acc= 1.0000 time= 0.0198\n",
      "Epoch: 0557 train_loss= 0.5754 train_acc= 1.0000 val_loss= 0.5754 val_acc= 1.0000 time= 0.0207\n",
      "Epoch: 0558 train_loss= 0.5741 train_acc= 1.0000 val_loss= 0.5741 val_acc= 1.0000 time= 0.0189\n",
      "Epoch: 0559 train_loss= 0.5737 train_acc= 1.0000 val_loss= 0.5737 val_acc= 1.0000 time= 0.0187\n",
      "Epoch: 0560 train_loss= 0.5750 train_acc= 1.0000 val_loss= 0.5750 val_acc= 1.0000 time= 0.0163\n",
      "Epoch: 0561 train_loss= 0.5767 train_acc= 1.0000 val_loss= 0.5767 val_acc= 1.0000 time= 0.0172\n",
      "Epoch: 0562 train_loss= 0.5771 train_acc= 1.0000 val_loss= 0.5771 val_acc= 1.0000 time= 0.0113\n",
      "Epoch: 0563 train_loss= 0.5749 train_acc= 1.0000 val_loss= 0.5749 val_acc= 1.0000 time= 0.0135\n",
      "Epoch: 0564 train_loss= 0.5722 train_acc= 1.0000 val_loss= 0.5722 val_acc= 1.0000 time= 0.0131\n",
      "Epoch: 0565 train_loss= 0.5709 train_acc= 1.0000 val_loss= 0.5709 val_acc= 1.0000 time= 0.0110\n",
      "Epoch: 0566 train_loss= 0.5725 train_acc= 1.0000 val_loss= 0.5725 val_acc= 1.0000 time= 0.0111\n",
      "Epoch: 0567 train_loss= 0.5753 train_acc= 1.0000 val_loss= 0.5753 val_acc= 1.0000 time= 0.0174\n",
      "Epoch: 0568 train_loss= 0.5767 train_acc= 1.0000 val_loss= 0.5767 val_acc= 1.0000 time= 0.0117\n",
      "Epoch: 0569 train_loss= 0.5747 train_acc= 1.0000 val_loss= 0.5747 val_acc= 1.0000 time= 0.0130\n",
      "Epoch: 0570 train_loss= 0.5714 train_acc= 1.0000 val_loss= 0.5714 val_acc= 1.0000 time= 0.0332\n",
      "Epoch: 0571 train_loss= 0.5697 train_acc= 1.0000 val_loss= 0.5697 val_acc= 1.0000 time= 0.0177\n",
      "Epoch: 0572 train_loss= 0.5710 train_acc= 1.0000 val_loss= 0.5710 val_acc= 1.0000 time= 0.0194\n",
      "Epoch: 0573 train_loss= 0.5731 train_acc= 1.0000 val_loss= 0.5731 val_acc= 1.0000 time= 0.0182\n",
      "Epoch: 0574 train_loss= 0.5745 train_acc= 1.0000 val_loss= 0.5745 val_acc= 1.0000 time= 0.0190\n",
      "Epoch: 0575 train_loss= 0.5734 train_acc= 1.0000 val_loss= 0.5734 val_acc= 1.0000 time= 0.0162\n",
      "Epoch: 0576 train_loss= 0.5713 train_acc= 1.0000 val_loss= 0.5713 val_acc= 1.0000 time= 0.0160\n",
      "Epoch: 0577 train_loss= 0.5694 train_acc= 1.0000 val_loss= 0.5694 val_acc= 1.0000 time= 0.0187\n",
      "Epoch: 0578 train_loss= 0.5691 train_acc= 1.0000 val_loss= 0.5691 val_acc= 1.0000 time= 0.0181\n",
      "Epoch: 0579 train_loss= 0.5699 train_acc= 1.0000 val_loss= 0.5699 val_acc= 1.0000 time= 0.0175\n",
      "Epoch: 0580 train_loss= 0.5710 train_acc= 1.0000 val_loss= 0.5710 val_acc= 1.0000 time= 0.0203\n",
      "Epoch: 0581 train_loss= 0.5715 train_acc= 1.0000 val_loss= 0.5715 val_acc= 1.0000 time= 0.0166\n",
      "Epoch: 0582 train_loss= 0.5716 train_acc= 1.0000 val_loss= 0.5716 val_acc= 1.0000 time= 0.0188\n",
      "Epoch: 0583 train_loss= 0.5712 train_acc= 1.0000 val_loss= 0.5712 val_acc= 1.0000 time= 0.0176\n",
      "Epoch: 0584 train_loss= 0.5701 train_acc= 1.0000 val_loss= 0.5701 val_acc= 1.0000 time= 0.0170\n",
      "Epoch: 0585 train_loss= 0.5689 train_acc= 1.0000 val_loss= 0.5689 val_acc= 1.0000 time= 0.0173\n",
      "Epoch: 0586 train_loss= 0.5689 train_acc= 1.0000 val_loss= 0.5689 val_acc= 1.0000 time= 0.0166\n",
      "Epoch: 0587 train_loss= 0.5701 train_acc= 1.0000 val_loss= 0.5701 val_acc= 1.0000 time= 0.0185\n",
      "Epoch: 0588 train_loss= 0.5709 train_acc= 1.0000 val_loss= 0.5709 val_acc= 1.0000 time= 0.0188\n",
      "Epoch: 0589 train_loss= 0.5698 train_acc= 1.0000 val_loss= 0.5698 val_acc= 1.0000 time= 0.0162\n",
      "Epoch: 0590 train_loss= 0.5679 train_acc= 1.0000 val_loss= 0.5679 val_acc= 1.0000 time= 0.0187\n",
      "Epoch: 0591 train_loss= 0.5679 train_acc= 1.0000 val_loss= 0.5679 val_acc= 1.0000 time= 0.0165\n",
      "Epoch: 0592 train_loss= 0.5694 train_acc= 1.0000 val_loss= 0.5694 val_acc= 1.0000 time= 0.0254\n",
      "Epoch: 0593 train_loss= 0.5698 train_acc= 1.0000 val_loss= 0.5698 val_acc= 1.0000 time= 0.0337\n",
      "Epoch: 0594 train_loss= 0.5686 train_acc= 1.0000 val_loss= 0.5686 val_acc= 1.0000 time= 0.0343\n",
      "Epoch: 0595 train_loss= 0.5683 train_acc= 1.0000 val_loss= 0.5683 val_acc= 1.0000 time= 0.0295\n",
      "Epoch: 0596 train_loss= 0.5683 train_acc= 1.0000 val_loss= 0.5683 val_acc= 1.0000 time= 0.0290\n",
      "Epoch: 0597 train_loss= 0.5683 train_acc= 1.0000 val_loss= 0.5683 val_acc= 1.0000 time= 0.0249\n",
      "Epoch: 0598 train_loss= 0.5669 train_acc= 1.0000 val_loss= 0.5669 val_acc= 1.0000 time= 0.0229\n",
      "Epoch: 0599 train_loss= 0.5654 train_acc= 1.0000 val_loss= 0.5654 val_acc= 1.0000 time= 0.0222\n",
      "Epoch: 0600 train_loss= 0.5652 train_acc= 1.0000 val_loss= 0.5652 val_acc= 1.0000 time= 0.0280\n",
      "Epoch: 0601 train_loss= 0.5665 train_acc= 1.0000 val_loss= 0.5665 val_acc= 1.0000 time= 0.0305\n",
      "Epoch: 0602 train_loss= 0.5673 train_acc= 1.0000 val_loss= 0.5673 val_acc= 1.0000 time= 0.0314\n",
      "Epoch: 0603 train_loss= 0.5668 train_acc= 1.0000 val_loss= 0.5668 val_acc= 1.0000 time= 0.0303\n",
      "Epoch: 0604 train_loss= 0.5658 train_acc= 1.0000 val_loss= 0.5658 val_acc= 1.0000 time= 0.0241\n",
      "Epoch: 0605 train_loss= 0.5642 train_acc= 1.0000 val_loss= 0.5642 val_acc= 1.0000 time= 0.0228\n",
      "Epoch: 0606 train_loss= 0.5633 train_acc= 1.0000 val_loss= 0.5633 val_acc= 1.0000 time= 0.0246\n",
      "Epoch: 0607 train_loss= 0.5637 train_acc= 1.0000 val_loss= 0.5637 val_acc= 1.0000 time= 0.0231\n",
      "Epoch: 0608 train_loss= 0.5645 train_acc= 1.0000 val_loss= 0.5645 val_acc= 1.0000 time= 0.0258\n",
      "Epoch: 0609 train_loss= 0.5643 train_acc= 1.0000 val_loss= 0.5643 val_acc= 1.0000 time= 0.0271\n",
      "Epoch: 0610 train_loss= 0.5635 train_acc= 1.0000 val_loss= 0.5635 val_acc= 1.0000 time= 0.0257\n",
      "Epoch: 0611 train_loss= 0.5639 train_acc= 1.0000 val_loss= 0.5639 val_acc= 1.0000 time= 0.0232\n",
      "Epoch: 0612 train_loss= 0.5638 train_acc= 1.0000 val_loss= 0.5638 val_acc= 1.0000 time= 0.0147\n",
      "Epoch: 0613 train_loss= 0.5631 train_acc= 1.0000 val_loss= 0.5631 val_acc= 1.0000 time= 0.0390\n",
      "Epoch: 0614 train_loss= 0.5624 train_acc= 1.0000 val_loss= 0.5624 val_acc= 1.0000 time= 0.0185\n",
      "Epoch: 0615 train_loss= 0.5628 train_acc= 1.0000 val_loss= 0.5628 val_acc= 1.0000 time= 0.0137\n",
      "Epoch: 0616 train_loss= 0.5625 train_acc= 1.0000 val_loss= 0.5625 val_acc= 1.0000 time= 0.0158\n",
      "Epoch: 0617 train_loss= 0.5623 train_acc= 1.0000 val_loss= 0.5623 val_acc= 1.0000 time= 0.0235\n",
      "Epoch: 0618 train_loss= 0.5626 train_acc= 1.0000 val_loss= 0.5626 val_acc= 1.0000 time= 0.0200\n",
      "Epoch: 0619 train_loss= 0.5627 train_acc= 1.0000 val_loss= 0.5627 val_acc= 1.0000 time= 0.0188\n",
      "Epoch: 0620 train_loss= 0.5623 train_acc= 1.0000 val_loss= 0.5623 val_acc= 1.0000 time= 0.0183\n",
      "Epoch: 0621 train_loss= 0.5623 train_acc= 1.0000 val_loss= 0.5623 val_acc= 1.0000 time= 0.0183\n",
      "Epoch: 0622 train_loss= 0.5624 train_acc= 1.0000 val_loss= 0.5624 val_acc= 1.0000 time= 0.0187\n",
      "Epoch: 0623 train_loss= 0.5614 train_acc= 1.0000 val_loss= 0.5614 val_acc= 1.0000 time= 0.0189\n",
      "Epoch: 0624 train_loss= 0.5601 train_acc= 1.0000 val_loss= 0.5601 val_acc= 1.0000 time= 0.0214\n",
      "Epoch: 0625 train_loss= 0.5611 train_acc= 1.0000 val_loss= 0.5611 val_acc= 1.0000 time= 0.0206\n",
      "Epoch: 0626 train_loss= 0.5631 train_acc= 1.0000 val_loss= 0.5631 val_acc= 1.0000 time= 0.0197\n",
      "Epoch: 0627 train_loss= 0.5630 train_acc= 1.0000 val_loss= 0.5630 val_acc= 1.0000 time= 0.0176\n",
      "Epoch: 0628 train_loss= 0.5607 train_acc= 1.0000 val_loss= 0.5607 val_acc= 1.0000 time= 0.0169\n",
      "Epoch: 0629 train_loss= 0.5586 train_acc= 1.0000 val_loss= 0.5586 val_acc= 1.0000 time= 0.0176\n",
      "Epoch: 0630 train_loss= 0.5585 train_acc= 1.0000 val_loss= 0.5585 val_acc= 1.0000 time= 0.0191\n",
      "Epoch: 0631 train_loss= 0.5602 train_acc= 1.0000 val_loss= 0.5602 val_acc= 1.0000 time= 0.0228\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a15db10b102c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Predict on full dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Train / validation scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m                         \u001b[0;34m'Feeding from symbolic tensors is not '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m                         'supported with sparse inputs.')\n\u001b[0;32m-> 2703\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m             \u001b[0;31m# callable generated by Session._make_callable_from_options accepts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A1.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A1.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1\n",
    "\n",
    "# Testing\n",
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(\"Test set results:\",\n",
    "      \"loss= {:.4f}\".format(test_loss[0]),\n",
    "      \"accuracy= {:.4f}\".format(test_acc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local pooling filters...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Layers should have equal number of output tensors and output masks. Layer GCN3_1 has 1 output tensors and 4 output masks.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f4a7e0c62823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# print(base_network.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# input_a = Input(shape=input_shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mprocessed_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;31m# processed_b = base_network(input_b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/FL/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m    759\u001b[0m                                 \u001b[0;34m'and output masks. Layer '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' has'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                                 \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' output tensors '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                                 'and ' + str(len(output_masks)) + ' output masks.')\n\u001b[0m\u001b[1;32m    762\u001b[0m                     \u001b[0;31m# Update model updates and losses:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;31m# Keep track of updates that depend on the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Layers should have equal number of output tensors and output masks. Layer GCN3_1 has 1 output tensors and 4 output masks."
     ]
    }
   ],
   "source": [
    "def slice(x,index):\n",
    "    return x[:,:,index]\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    feature_input = Input(shape=(static_features.shape[1],), sparse=True, name = 'static_feature')\n",
    "    if FILTER == 'localpool':\n",
    "        \"\"\" Local pooling filters (see 'renormalization trick' in Kipf & Welling, arXiv 2016) \"\"\"\n",
    "        print('Using local pooling filters...')\n",
    "        A1_ = preprocess_adj(A1, SYM_NORM)\n",
    "        A2_ = preprocess_adj(A2, SYM_NORM)\n",
    "        A3_ = preprocess_adj(A3, SYM_NORM)\n",
    "        support = 1\n",
    "        graph = [X, A1,A2,A3]\n",
    "        G1 = [Input(shape=(None, None), batch_shape=(None, None), sparse=True, name = \"1stNeighbor\")]\n",
    "        G2 = [Input(shape=(None, None), batch_shape=(None, None), sparse=True, name = \"2ndNeighbor\")]\n",
    "        G3 = [Input(shape=(None, None), batch_shape=(None, None), sparse=True, name = \"3rdNeighbor\")]\n",
    "\n",
    "    elif FILTER == 'chebyshev':\n",
    "        \"\"\" Chebyshev polynomial basis filters (Defferard et al., NIPS 2016)  \"\"\"\n",
    "        print('Using Chebyshev polynomial basis filters...')\n",
    "        L = normalized_laplacian(A, SYM_NORM)\n",
    "        L_scaled = rescale_laplacian(L)\n",
    "        T_k = chebyshev_polynomial(L_scaled, MAX_DEGREE)\n",
    "        support = MAX_DEGREE + 1\n",
    "        graph = [X]+T_k\n",
    "        G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True) for _ in range(support)]\n",
    "\n",
    "    else:\n",
    "        raise Exception('Invalid filter type.')\n",
    "    X_in = Input(shape=input_shape)\n",
    "    X1 = layers.LSTM(1, return_sequences = True, name = 'LSTM')(X_in)\n",
    "    H = layers.Lambda(slice,arguments={'index':-1}, name = 'squeeze')(X1)\n",
    "    H1 = GraphConvolution(16, 1,support, activation='relu', kernel_regularizer=l2(5e-4), name = 'GCN1_1')([H]+G1+G2+G3)\n",
    "    H2 = GraphConvolution(16, 2,support, activation='relu', kernel_regularizer=l2(5e-4), name = 'GCN2_1')([H]+G1+G2+G3)\n",
    "    H3 = GraphConvolution(16, 3,support, activation='relu', kernel_regularizer=l2(5e-4), name = 'GCN3_1')([H]+G1+G2+G3)\n",
    "    Y1 = GraphConvolution(y.shape[1],1 ,support, name = 'GCN1_2')([H1]+G1+G2+G3)\n",
    "    Y2 = GraphConvolution(y.shape[1],2, support, name = 'GCN2_2')([H2]+G1+G2+G3)\n",
    "    Y3 = GraphConvolution(y.shape[1],3, support, name = 'GCN3_2')([H3]+G1+G2+G3)\n",
    "    Y = Concatenate(name=\"concatStaticFeature\")([Y1,Y2,Y3,feature_input])\n",
    "    Y = Dense(y.shape[1], name=\"outPut\")(Y)\n",
    "    model = Model(inputs=[X_in]+G1+G2+G3+[feature_input], outputs=Y)\n",
    "    return model\n",
    "\n",
    "# Siamese RNN\n",
    "# input_shape = (2015,1)\n",
    "\n",
    "base_network = create_base_network((car_flow_feature.shape[1:]))\n",
    "\n",
    "feature_input = Input(shape=(static_features.shape[1],), sparse=True, name = 'static_feature')\n",
    "X_in = Input(shape=input_shape)\n",
    "G1 = [Input(shape=(None, None), batch_shape=(None, None), sparse=True, name = \"1stNeighbor\")]\n",
    "G2 = [Input(shape=(None, None), batch_shape=(None, None), sparse=True, name = \"2ndNeighbor\")]\n",
    "G3 = [Input(shape=(None, None), batch_shape=(None, None), sparse=True, name = \"3rdNeighbor\")]\n",
    "\n",
    "input_a = [X_in]+G1+G2+G3+[feature_input]\n",
    "# print(base_network.summary())\n",
    "# input_a = Input(shape=input_shape)\n",
    "processed_a = base_network(input_a)\n",
    "# processed_b = base_network(input_b)\n",
    "\n",
    "# distance = Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "# model = Model([input_a, input_b], outputs=processed_a)\n",
    "\n",
    "# # model = Model(inputs=[X_in]+G1+G2+G3, outputs=Y)\n",
    "\n",
    "# base_network.compile(loss='mse', optimizer=Adam(lr=0.001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice(x,index):\n",
    "    return x[:,index]\n",
    "input_shape = (17, 12, 4)\n",
    "output_shape = (1)\n",
    "# 第一个输入\n",
    "feature_input = Input(\n",
    "    shape=(static_features.shape), name='static_feature')\n",
    "feature_input_low = layers.Lambda(slice, arguments={'index': -1}, name='squeeze0')(feature_input)\n",
    "\n",
    "support = 1\n",
    "\n",
    "if FILTER == 'localpool':\n",
    "    \"\"\" Local pooling filters (see 'renormalization trick' in Kipf & Welling, arXiv 2016) \"\"\"\n",
    "#     print('Using local pooling filters...')\n",
    "\n",
    "    G1 = [Input(shape=(None, None), batch_shape=(\n",
    "        None, None), sparse=True, name=\"1stNeighbor\")]\n",
    "    G2 = [Input(shape=(None, None), batch_shape=(\n",
    "        None, None), sparse=True, name=\"2ndNeighbor\")]\n",
    "    G3 = [Input(shape=(None, None), batch_shape=(\n",
    "        None, None), sparse=True, name=\"3rdNeighbor\")]\n",
    "elif FILTER == 'chebyshev':\n",
    "    \"\"\" Chebyshev polynomial basis filters (Defferard et al., NIPS 2016)  \"\"\"\n",
    "    pass\n",
    "else:\n",
    "    raise Exception('Invalid filter type.')\n",
    "X_in = Input(shape=input_shape)\n",
    "X1 = layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape)(X_in)\n",
    "X2 = layers.MaxPooling2D((2, 2))(X1)\n",
    "\n",
    "H = layers.Lambda(slice, arguments={'index': -1}, name='squeeze1')(X2)\n",
    "H = layers.Lambda(slice, arguments={'index': -1}, name='squeeze2')(H)\n",
    "# H = X3\n",
    "H1 = GraphConvolution(16, 1, support, activation='relu',\n",
    "                      kernel_regularizer=l2(5e-4), name='GCN1_1')([H]+G1+G2+G3)\n",
    "H2 = GraphConvolution(16, 2, support, activation='relu',\n",
    "                      kernel_regularizer=l2(5e-4), name='GCN2_1')([H]+G1+G2+G3)\n",
    "H3 = GraphConvolution(16, 3, support, activation='relu',\n",
    "                      kernel_regularizer=l2(5e-4), name='GCN3_1')([H]+G1+G2+G3)\n",
    "Y1 = GraphConvolution(y.shape[1], 1, support, name='GCN1_2')([H1]+G1+G2+G3)\n",
    "Y2 = GraphConvolution(y.shape[1], 2, support, name='GCN2_2')([H2]+G1+G2+G3)\n",
    "Y3 = GraphConvolution(y.shape[1], 3, support, name='GCN3_2')([H3]+G1+G2+G3)\n",
    "Y = Concatenate(name=\"concatStaticFeature\")([Y1, Y2, Y3, feature_input_low])\n",
    "output_layer = Dense(output_shape, name=\"outPut\")(Y)\n",
    "\n",
    "# 第二个输入\n",
    "feature_input_ = Input(\n",
    "    shape=(static_features.shape), name='static_feature_')\n",
    "feature_input_low_ = layers.Lambda(slice, arguments={'index': -1}, name='squeeze0_')(feature_input_)\n",
    "\n",
    "if FILTER == 'localpool':\n",
    "    \"\"\" Local pooling filters (see 'renormalization trick' in Kipf & Welling, arXiv 2016) \"\"\"\n",
    "#     print('Using local pooling filters...')\n",
    "\n",
    "    G1_ = [Input(shape=(None, None), batch_shape=(\n",
    "        None, None), sparse=True, name=\"1stNeighbor_\")]\n",
    "    G2_ = [Input(shape=(None, None), batch_shape=(\n",
    "        None, None), sparse=True, name=\"2ndNeighbor_\")]\n",
    "    G3_ = [Input(shape=(None, None), batch_shape=(\n",
    "        None, None), sparse=True, name=\"3rdNeighbor_\")]\n",
    "elif FILTER == 'chebyshev':\n",
    "    \"\"\" Chebyshev polynomial basis filters (Defferard et al., NIPS 2016)  \"\"\"\n",
    "    pass\n",
    "else:\n",
    "    raise Exception('Invalid filter type.')\n",
    "X_in_ = Input(shape=input_shape)\n",
    "X1_ = layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape)(X_in_)\n",
    "X2_ = layers.MaxPooling2D((2, 2))(X1_)\n",
    "\n",
    "H_ = layers.Lambda(slice, arguments={'index': -1}, name='squeeze1_')(X2_)\n",
    "H_ = layers.Lambda(slice, arguments={'index': -1}, name='squeeze2_')(H_)\n",
    "# H = X3\n",
    "H1_ = GraphConvolution(16, 1, support, activation='relu',\n",
    "                      kernel_regularizer=l2(5e-4), name='GCN1_1')([H_]+G1_+G2_+G3_)\n",
    "H2_ = GraphConvolution(16, 2, support, activation='relu', kernel_regularizer=l2(\n",
    "    5e-4), name='GCN2_1_')([H_]+G1_+G2_+G3_)\n",
    "H3_ = GraphConvolution(16, 3, support, activation='relu', kernel_regularizer=l2(\n",
    "    5e-4), name='GCN3_1_')([H_]+G1_+G2_+G3_)\n",
    "Y1_ = GraphConvolution(y.shape[1], 1, support,\n",
    "                       name='GCN1_2_')([H_]+G1_+G2_+G3_)\n",
    "Y2_ = GraphConvolution(y.shape[1], 2, support,\n",
    "                       name='GCN2_2_')([H_]+G1_+G2_+G3_)\n",
    "Y3_ = GraphConvolution(y.shape[1], 3, support,\n",
    "                       name='GCN3_2_')([H_]+G1_+G2_+G3_)\n",
    "Y_ = Concatenate(name=\"concatStaticFeature_\")([Y1_, Y2_, Y3_, feature_input_low_])\n",
    "output_layer_ = Dense(output_shape, name=\"outPut_\")(Y_)\n",
    "\n",
    "\n",
    "distance = Lambda(euclidean_distance, output_shape=(1,), name=\"distance\")([output_layer, output_layer_])\n",
    "final_output = Dense(units = 1,name=\"final_outPut\")(distance)\n",
    "all_input = [X_in]+G1+G2+G3+[feature_input] + \\\n",
    "    [X_in_]+G1_+G2_+G3_+[feature_input_]\n",
    "model = Model(inputs=all_input, outputs=final_output)\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "22a64583531ba634a038646f06d5ec4438ad380206cf212e394775f1d0eaad28"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('new_traffic6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
